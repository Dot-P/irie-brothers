{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e7f054",
   "metadata": {},
   "source": [
    "# 応用情報工学演習：Scikit-Learnマスターコース\n",
    "## 実践編 配布用コードファイル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05475811",
   "metadata": {},
   "source": [
    "#### 基本ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29e49b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "\n",
    "# 自作モジュールのインポート\n",
    "from utils.train import fit, evaluate_history, generate_pseudo_labels ,torch_seed, fit_self_train\n",
    "from utils.dataset import MyDataset\n",
    "\n",
    "# 必要ライブラリのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch関連ライブラリのインポート\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# warning表示off\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# デフォルトフォントサイズ変更\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# デフォルトグラフサイズ変更\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# デフォルトで方眼表示ON\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# numpyの表示桁数設定\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c439ac",
   "metadata": {},
   "source": [
    "### Cudaのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9188925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a261d",
   "metadata": {},
   "source": [
    "#### データ読み込み関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42558127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-#\n",
    "#                               このセルは変更を禁止します                                  #\n",
    "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-#\n",
    "#-------------------------------------------------------------------------------------------#\n",
    "#-                                  データ読み込み関数                                     -#\n",
    "#-------------------------------------------------------------------------------------------#\n",
    "def load_data_(root_dir='../data/gw_dataset'):\n",
    "    \"\"\"\n",
    "    グループワーク用　学習用データ読み込み関数\n",
    "\n",
    "    Args:\n",
    "        * root_dir: 配布したgw_datasetへのパスを指定する (default: '../data/gw_dataset')\n",
    "        \n",
    "    Output:\n",
    "        * X_train:  正解ラベル付き学習用画像   shape: (140x150,528)\n",
    "                    1行あたり、画像1枚の画素値を格納したnp.array\n",
    "                    画像140枚、各画像224x224=150,528次元のベクトル\n",
    "                    \n",
    "        * y_train:  X_trainの正解ラベル        shape: (140, )\n",
    "                    クラス数は7　140枚分のクラスラベル（0～6）の整数が格納されている\n",
    "        \n",
    "        * X_trainu: 正解ラベルなし学習用画像   shape: (210x150,528)\n",
    "                    形式はX_trainと同じ\n",
    "                    \n",
    "        * X_val:   正解ラベル付き検証用画像   shape: (70x150,528)\n",
    "                    形式はX_trainと同じ\n",
    "                    \n",
    "        * y_val:    X_valの正解ラベル          shape: (70, )\n",
    "                    形式はy_valと同じ                             \n",
    "    \"\"\"\n",
    "    \n",
    "    #----------------- 学習用データの読み込み -------------------#\n",
    "    train_paths = sorted(glob.glob(os.path.join(root_dir, \"train\", \"*.png\")))\n",
    "    \n",
    "    X_train = np.array([np.array(Image.open(p)).astype(np.float32).ravel() for p in train_paths])\n",
    "    y_train = np.load(os.path.join(root_dir, \"y_train.npy\"))\n",
    "\n",
    "    #------------ ラベルなし学習用データの読み込み --------------#\n",
    "    trainu_paths = sorted(glob.glob(os.path.join(root_dir, \"train-u\", \"*.png\")))\n",
    "    X_trainu = np.array([np.array(Image.open(p)).astype(np.float32).ravel() for p in trainu_paths])\n",
    "    \n",
    "    #----------------- 検証用データの読み込み -------------------#\n",
    "    val_paths = sorted(glob.glob(os.path.join(root_dir,\"val\", \"*.png\")))\n",
    "    X_val = np.array([np.array(Image.open(p)).astype(np.float32).ravel() for p in val_paths])\n",
    "    y_val = np.load(os.path.join(root_dir, \"y_val.npy\"))\n",
    "\n",
    "    return X_train, y_train, X_trainu, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f4ef9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 150528) (140,) (210, 150528) (70, 150528) (70,)\n"
     ]
    }
   ],
   "source": [
    "### データ読み込み関数の実行\n",
    "X_train, y_train, X_trainu, X_val, y_val = load_data_() # すべて必要な場合\n",
    "print(X_train.shape, y_train.shape, X_trainu.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "# X_train, y_train, _, X_val, y_val = load_data_() # いらないデータがある場合\n",
    "# print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fa050",
   "metadata": {},
   "source": [
    "#### 評価関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22a0fbcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-#\n",
    "#                               このセルは変更を禁止します                                  #\n",
    "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-#\n",
    "#-------------------------------------------------------------------------------------------#\n",
    "#-                                       評価関数                                          -#\n",
    "#-------------------------------------------------------------------------------------------#\n",
    "\n",
    "def eval_(y_pred):\n",
    "    \"\"\"\n",
    "    グループワーク用　評価関数\n",
    "    実行する前にy_valがglobalスコープに読み込まれている必要がある\n",
    "\n",
    "    Args:\n",
    "        * y_pred:   識別結果　y_valと同形式・同shapeでなければならない\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        y_val\n",
    "    except NameError as e:\n",
    "        print(\"y_valが読み込まれていません\")\n",
    "        \n",
    "    assert y_pred.shape == y_val.shape, 'y_predとy_valのサイズが一致しません'\n",
    "    \n",
    "    print(\"valデータでの識別精度:{0:.3f}\".format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a95cdb",
   "metadata": {},
   "source": [
    "### データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7df4ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ: 140件\n",
      "ラベルなし訓練データ: 210件\n",
      "検証データ: 70件\n"
     ]
    }
   ],
   "source": [
    "# 分類先クラスのリスト作成\n",
    "classes = [ '0', '1', '2', '3', '4', '5', '6']\n",
    "\n",
    "# データを復元\n",
    "X_train_reshaped = X_train.reshape(-1, 224, 224, 3)\n",
    "X_val_reshaped = X_val.reshape(-1, 224, 224, 3)\n",
    "X_trainu_reshaped = X_trainu.reshape(-1, 224, 224, 3)\n",
    "\n",
    "# データセット作成\n",
    "train_data = MyDataset(X_train_reshaped, y_train, type='no_trans')\n",
    "val_data = MyDataset(X_val_reshaped, y_val, type='val')\n",
    "trainu_data = MyDataset(X_trainu_reshaped, None, type='no_trans')\n",
    "\n",
    "# データ件数確認\n",
    "print(f'訓練データ: {len(train_data)}件')\n",
    "print(f'ラベルなし訓練データ: {len(trainu_data)}件')\n",
    "print(f'検証データ: {len(val_data)}件')\n",
    "\n",
    "# データローダー作成\n",
    "batch_size = 70\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "unlabeled_loader = DataLoader(trainu_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4962e0",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8606571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 試行回数\n",
    "num_epochs = 2000\n",
    "\n",
    "# Consistency regularizationの重み\n",
    "lambda_u = 0\n",
    "\n",
    "# historyファイルを初期化する\n",
    "history = np.zeros((0, 5), dtype=float)\n",
    "\n",
    "# 学習モデル定義\n",
    "net = models.resnet18(pretrained = True)\n",
    "net.fc = nn.Linear(in_features=net.fc.in_features, out_features=7)  # 7クラスに変更\n",
    "\n",
    "# 乱数初期化\n",
    "torch_seed()\n",
    "\n",
    "# GPUの利用\n",
    "net = net.to(device)\n",
    "\n",
    "# 学習率\n",
    "lr = 1e-4\n",
    "\n",
    "# 損失関数定義\n",
    "ce = nn.CrossEntropyLoss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# 最適化関数定義\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5fe30",
   "metadata": {},
   "source": [
    "### Π-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1acb5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "strong_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd58fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000: Train Loss: 0.0256, Train Acc: 0.2000, Val Loss: 0.0258, Val Acc: 0.2143\n",
      "Epoch 2/2000: Train Loss: 0.0157, Train Acc: 0.8357, Val Loss: 0.0221, Val Acc: 0.3714\n",
      "Epoch 3/2000: Train Loss: 0.0064, Train Acc: 0.9571, Val Loss: 0.0178, Val Acc: 0.5857\n",
      "Epoch 4/2000: Train Loss: 0.0021, Train Acc: 0.9786, Val Loss: 0.0141, Val Acc: 0.6143\n",
      "Epoch 5/2000: Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0169, Val Acc: 0.5857\n",
      "Epoch 6/2000: Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0111, Val Acc: 0.7000\n",
      "Epoch 7/2000: Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7429\n",
      "Epoch 8/2000: Train Loss: 0.0036, Train Acc: 0.8857, Val Loss: 0.0325, Val Acc: 0.5000\n",
      "Epoch 9/2000: Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.6571\n",
      "Epoch 10/2000: Train Loss: 0.0007, Train Acc: 0.9786, Val Loss: 0.0157, Val Acc: 0.6571\n",
      "Epoch 11/2000: Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0169, Val Acc: 0.5857\n",
      "Epoch 12/2000: Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.6857\n",
      "Epoch 13/2000: Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0106, Val Acc: 0.7429\n",
      "Epoch 14/2000: Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0114, Val Acc: 0.7000\n",
      "Epoch 15/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7143\n",
      "Epoch 16/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0150, Val Acc: 0.7000\n",
      "Epoch 17/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0159, Val Acc: 0.7000\n",
      "Epoch 18/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0162, Val Acc: 0.7286\n",
      "Epoch 19/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0160, Val Acc: 0.7857\n",
      "Epoch 20/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0152, Val Acc: 0.7857\n",
      "Epoch 21/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7857\n",
      "Epoch 22/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7857\n",
      "Epoch 23/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7857\n",
      "Epoch 24/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7714\n",
      "Epoch 25/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7714\n",
      "Epoch 26/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7429\n",
      "Epoch 27/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 28/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 29/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 30/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 31/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7429\n",
      "Epoch 32/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7429\n",
      "Epoch 33/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 34/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 35/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 36/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7714\n",
      "Epoch 37/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7714\n",
      "Epoch 38/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7714\n",
      "Epoch 39/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7714\n",
      "Epoch 40/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 41/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 42/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 43/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 44/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 45/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 46/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 47/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 48/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 49/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 50/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 51/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 52/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 53/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 54/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 55/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 56/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7714\n",
      "Epoch 57/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 58/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 59/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 60/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 61/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 62/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 63/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 64/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 65/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 66/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 67/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 0.7571\n",
      "Epoch 68/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 69/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 70/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 71/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 72/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 73/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 74/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 75/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 76/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 77/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 78/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 79/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 80/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 81/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 82/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 83/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 84/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 85/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 86/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 87/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 88/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0119, Val Acc: 0.7571\n",
      "Epoch 89/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 90/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 91/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 92/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 93/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 94/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 95/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 96/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 97/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 98/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 99/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 100/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 101/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 102/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 103/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 104/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 105/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 106/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 107/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 108/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 109/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0120, Val Acc: 0.7571\n",
      "Epoch 110/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 111/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 112/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 113/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 114/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 115/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 116/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 117/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 118/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 119/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 120/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 121/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 122/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 123/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 124/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 125/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 126/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 127/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 128/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 129/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 130/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 131/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 132/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0121, Val Acc: 0.7571\n",
      "Epoch 133/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 134/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 135/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 136/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 137/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 138/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 139/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 140/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 141/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 142/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 143/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 144/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 145/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 146/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 147/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 148/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 149/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 150/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 151/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 152/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 153/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 154/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 155/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 156/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 157/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 158/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 159/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 160/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0122, Val Acc: 0.7571\n",
      "Epoch 161/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 162/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 163/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 164/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 165/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 166/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 167/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 168/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 169/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 170/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 171/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 172/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 173/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 174/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 175/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 176/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 177/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 178/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 179/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 180/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 181/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 182/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 183/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 184/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 185/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 186/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 187/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 188/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 189/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 190/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 191/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0123, Val Acc: 0.7571\n",
      "Epoch 192/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 193/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 194/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 195/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 196/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 197/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 198/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 199/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 200/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 201/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 202/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 203/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 204/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 205/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 206/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 207/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 208/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 209/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 210/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 211/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 212/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 213/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 214/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 215/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 216/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 217/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 218/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 219/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 220/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 221/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 222/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 223/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 224/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 225/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 226/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 227/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0124, Val Acc: 0.7571\n",
      "Epoch 228/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 229/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 230/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 231/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 232/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 233/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 234/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 235/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 236/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 237/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 238/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 239/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 240/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 241/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 242/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 243/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 244/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 245/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 246/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 247/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 248/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 249/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 250/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 251/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 252/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 253/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 254/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 255/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 256/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 257/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 258/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 259/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 260/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 261/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 262/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 263/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 264/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 265/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 266/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 267/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 268/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0125, Val Acc: 0.7571\n",
      "Epoch 269/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 270/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 271/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 272/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 273/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 274/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 275/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 276/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 277/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 278/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 279/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 280/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 281/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 282/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 283/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 284/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 285/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 286/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 287/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 288/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 289/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 290/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 291/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 292/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 293/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 294/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 295/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 296/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 297/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 298/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 299/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 300/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 301/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 302/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 303/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 304/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 305/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 306/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 307/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 308/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 309/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 310/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 311/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 312/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 313/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 314/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0126, Val Acc: 0.7571\n",
      "Epoch 315/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 316/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 317/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 318/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 319/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 320/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 321/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 322/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 323/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 324/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 325/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 326/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 327/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 328/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 329/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 330/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 331/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 332/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 333/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 334/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 335/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 336/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 337/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 338/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 339/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 340/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 341/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 342/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 343/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 344/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 345/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 346/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 347/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 348/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 349/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 350/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 351/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 352/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 353/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 354/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 355/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 356/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 357/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 358/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 359/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 360/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 361/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0127, Val Acc: 0.7571\n",
      "Epoch 362/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 363/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 364/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 365/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 366/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 367/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 368/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 369/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 370/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 371/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 372/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 373/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 374/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 375/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 376/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 377/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 378/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 379/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 380/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 381/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 382/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 383/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 384/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 385/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 386/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 387/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 388/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 389/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 390/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 391/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 392/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 393/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 394/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 395/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 396/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 397/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 398/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 399/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 400/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 401/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 402/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 403/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 404/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 405/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 406/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 407/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 408/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 409/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 410/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 411/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 412/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 413/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 0.7571\n",
      "Epoch 414/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 415/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 416/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 417/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 418/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 419/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 420/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 421/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 422/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 423/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 424/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 425/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 426/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 427/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 428/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 429/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 430/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 431/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 432/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 433/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 434/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 435/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 436/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 437/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 438/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 439/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 440/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 441/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 442/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 443/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 444/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 445/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 446/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 447/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 448/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 449/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 450/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 451/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7571\n",
      "Epoch 452/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 453/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 454/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 455/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 456/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 457/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 458/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 459/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 460/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 461/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 462/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 463/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 464/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 465/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 466/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 467/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 468/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 469/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 470/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 471/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0129, Val Acc: 0.7714\n",
      "Epoch 472/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 473/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 474/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 475/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 476/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 477/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 478/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 479/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 480/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 481/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 482/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 483/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 484/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 485/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 486/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 487/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 488/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 489/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 490/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 491/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 492/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 493/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 494/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 495/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 496/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 497/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 498/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 499/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 500/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 501/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 502/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 503/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 504/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 505/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 506/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 507/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 508/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 509/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 510/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 511/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 512/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 513/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 514/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 515/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 516/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 517/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 518/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 519/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 520/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 521/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 522/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 523/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 524/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 525/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 526/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 527/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 528/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 529/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 530/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 531/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0130, Val Acc: 0.7714\n",
      "Epoch 532/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 533/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 534/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 535/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 536/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 537/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 538/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 539/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 540/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 541/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 542/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 543/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 544/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 545/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 546/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 547/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 548/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 549/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 550/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 551/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 552/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 553/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 554/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 555/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 556/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 557/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 558/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 559/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 560/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 561/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 562/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 563/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 564/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 565/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 566/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 567/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 568/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 569/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 570/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 571/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 572/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 573/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 574/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 575/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 576/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 577/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 578/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 579/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 580/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 581/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 582/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 583/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 584/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 585/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 586/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 587/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 588/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 589/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 590/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 591/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 592/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 593/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 594/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 595/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0131, Val Acc: 0.7714\n",
      "Epoch 596/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 597/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 598/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 599/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 600/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 601/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 602/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 603/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 604/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 605/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 606/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 607/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 608/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 609/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 610/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 611/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 612/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 613/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 614/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 615/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 616/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 617/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 618/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 619/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 620/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 621/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 622/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 623/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 624/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 625/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 626/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 627/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 628/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 629/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 630/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 631/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 632/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 633/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 634/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 635/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 636/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 637/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 638/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 639/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 640/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 641/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 642/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 643/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 644/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 645/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 646/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 647/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 648/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 649/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 650/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 651/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 652/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 653/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 654/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 655/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 656/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 657/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 658/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 659/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 660/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 661/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0132, Val Acc: 0.7714\n",
      "Epoch 662/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 663/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 664/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 665/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 666/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 667/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 668/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 669/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 670/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 671/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 672/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 673/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 674/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 675/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 676/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 677/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 678/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 679/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 680/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 681/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 682/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 683/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 684/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 685/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 686/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 687/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 688/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 689/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 690/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 691/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 692/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 693/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 694/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 695/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 696/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 697/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 698/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 699/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 700/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 701/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 702/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 703/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 704/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 705/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 706/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 707/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 708/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 709/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 710/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 711/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 712/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 713/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 714/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 715/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 716/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 717/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 718/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 719/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 720/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 721/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 722/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 723/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 724/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 725/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 726/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 727/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 728/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 729/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 730/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 731/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 732/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 733/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 734/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 0.7714\n",
      "Epoch 735/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 736/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 737/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 738/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 739/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 740/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 741/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 742/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 743/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 744/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 745/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 746/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 747/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 748/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 749/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 750/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 751/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 752/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 753/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 754/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 755/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 756/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 757/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 758/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 759/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 760/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 761/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 762/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 763/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 764/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 765/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 766/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 767/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 768/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 769/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 770/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 771/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 772/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 773/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 774/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 775/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 776/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 777/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 778/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 779/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 780/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 781/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 782/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 783/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 784/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 785/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 786/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 787/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 788/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 789/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 790/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 791/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 792/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 793/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 794/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 795/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 796/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 797/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 798/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 799/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 800/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 801/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 802/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 803/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 804/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 805/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 806/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 807/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 808/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 809/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 810/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 811/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 812/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0134, Val Acc: 0.7714\n",
      "Epoch 813/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 814/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 815/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 816/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 817/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 818/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 819/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 820/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 821/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 822/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 823/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 824/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 825/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 826/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 827/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 828/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 829/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 830/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 831/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 832/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 833/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 834/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 835/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 836/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 837/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 838/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 839/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 840/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 841/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 842/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 843/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 844/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 845/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 846/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 847/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 848/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 849/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 850/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 851/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 852/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 853/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 854/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 855/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 856/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 857/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 858/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 859/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 860/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 861/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 862/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 863/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 864/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 865/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 866/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 867/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 868/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 869/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 870/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 871/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 872/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 873/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 874/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 875/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 876/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 877/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 878/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 879/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 880/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 881/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 882/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 883/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 884/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 885/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 886/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 887/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 888/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 889/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 890/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 891/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 892/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 893/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 894/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 895/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0135, Val Acc: 0.7714\n",
      "Epoch 896/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 897/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 898/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 899/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 900/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 901/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 902/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 903/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 904/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 905/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 906/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 907/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 908/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 909/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 910/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 911/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 912/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 913/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 914/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 915/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 916/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 917/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 918/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 919/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 920/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 921/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 922/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 923/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 924/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 925/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 926/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 927/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 928/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 929/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 930/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 931/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 932/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 933/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 934/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 935/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 936/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 937/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 938/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 939/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 940/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 941/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 942/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 943/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 944/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 945/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 946/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 947/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 948/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 949/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 950/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 951/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 952/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 953/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 954/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 955/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 956/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 957/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 958/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 959/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 960/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 961/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 962/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 963/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 964/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 965/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 966/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 967/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 968/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 969/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 970/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 971/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 972/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 973/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 974/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 975/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 976/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 977/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 978/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 979/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0136, Val Acc: 0.7714\n",
      "Epoch 980/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 981/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 982/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 983/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 984/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 985/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 986/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 987/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 988/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 989/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 990/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 991/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 992/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 993/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 994/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 995/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 996/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 997/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 998/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 999/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1000/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1001/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1002/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1003/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1004/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1005/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1006/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1007/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1008/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1009/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1010/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1011/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1012/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1013/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1014/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1015/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1016/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1017/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1018/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1019/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1020/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1021/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1022/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1023/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1024/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1025/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1026/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1027/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1028/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1029/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1030/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1031/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1032/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1033/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1034/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1035/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1036/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1037/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1038/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1039/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1040/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1041/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1042/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1043/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1044/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1045/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1046/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1047/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1048/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1049/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1050/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1051/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1052/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1053/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1054/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1055/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1056/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1057/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1058/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1059/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1060/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1061/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1062/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1063/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1064/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1065/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1066/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1067/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1068/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1069/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1070/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1071/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1072/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1073/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1074/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1075/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1076/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1077/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1078/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1079/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 0.7714\n",
      "Epoch 1080/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1081/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1082/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1083/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1084/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1085/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1086/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1087/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1088/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1089/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1090/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1091/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1092/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1093/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1094/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1095/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1096/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1097/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1098/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1099/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1100/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1101/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1102/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1103/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1104/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1105/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1106/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1107/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1108/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1109/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1110/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1111/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1112/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1113/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1114/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1115/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1116/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1117/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1118/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1119/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1120/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1121/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1122/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1123/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1124/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1125/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1126/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1127/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1128/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1129/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1130/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1131/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1132/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1133/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1134/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1135/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1136/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1137/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1138/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1139/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1140/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1141/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1142/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1143/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1144/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1145/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1146/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1147/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1148/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1149/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1150/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1151/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1152/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1153/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1154/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1155/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1156/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1157/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1158/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1159/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1160/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1161/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1162/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1163/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1164/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1165/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1166/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0138, Val Acc: 0.7714\n",
      "Epoch 1167/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1168/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1169/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1170/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1171/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1172/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1173/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1174/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1175/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1176/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1177/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1178/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1179/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1180/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1181/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1182/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1183/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1184/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1185/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1186/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1187/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1188/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1189/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1190/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1191/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1192/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1193/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1194/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1195/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1196/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1197/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1198/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1199/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1200/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1201/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1202/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1203/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1204/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1205/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1206/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1207/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1208/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1209/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1210/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1211/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1212/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1213/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1214/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1215/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1216/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1217/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1218/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1219/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1220/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1221/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1222/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1223/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1224/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1225/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1226/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1227/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1228/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1229/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1230/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1231/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1232/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1233/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1234/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1235/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1236/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1237/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1238/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1239/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1240/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1241/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1242/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1243/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1244/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1245/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1246/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1247/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1248/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1249/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1250/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1251/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1252/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1253/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1254/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1255/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1256/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1257/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1258/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1259/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1260/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1261/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1262/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1263/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1264/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1265/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1266/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1267/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1268/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1269/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1270/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1271/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1272/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1273/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1274/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1275/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1276/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1277/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1278/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1279/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1280/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1281/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1282/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1283/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0139, Val Acc: 0.7714\n",
      "Epoch 1284/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1285/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1286/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1287/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1288/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1289/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1290/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1291/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1292/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1293/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1294/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1295/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1296/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1297/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1298/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1299/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1300/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1301/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1302/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1303/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1304/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1305/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1306/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1307/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1308/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1309/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1310/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1311/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1312/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1313/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1314/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1315/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1316/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1317/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1318/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1319/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1320/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1321/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1322/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1323/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1324/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1325/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1326/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1327/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1328/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1329/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1330/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1331/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1332/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1333/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1334/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1335/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1336/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1337/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1338/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1339/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1340/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1341/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1342/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1343/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1344/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1345/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1346/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1347/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1348/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1349/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1350/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1351/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1352/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1353/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1354/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1355/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1356/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1357/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1358/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1359/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1360/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1361/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1362/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1363/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1364/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1365/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1366/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1367/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1368/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1369/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1370/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1371/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1372/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1373/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0140, Val Acc: 0.7714\n",
      "Epoch 1374/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1375/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1376/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1377/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1378/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1379/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1380/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1381/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1382/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1383/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1384/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1385/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1386/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1387/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1388/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1389/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1390/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1391/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1392/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1393/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1394/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1395/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1396/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1397/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1398/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1399/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1400/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1401/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1402/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1403/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1404/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1405/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1406/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1407/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1408/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1409/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1410/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1411/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1412/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1413/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1414/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1415/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1416/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1417/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1418/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1419/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1420/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1421/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1422/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1423/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1424/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1425/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1426/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1427/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1428/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1429/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1430/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1431/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1432/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1433/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1434/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1435/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1436/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1437/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1438/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1439/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1440/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1441/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1442/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1443/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1444/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1445/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1446/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1447/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1448/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1449/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1450/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1451/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1452/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1453/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1454/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1455/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1456/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1457/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1458/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1459/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1460/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1461/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1462/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1463/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1464/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1465/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1466/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1467/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1468/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1469/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1470/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1471/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1472/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1473/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1474/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1475/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1476/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1477/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1478/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1479/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0141, Val Acc: 0.7714\n",
      "Epoch 1480/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1481/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1482/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1483/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1484/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1485/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1486/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1487/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1488/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1489/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1490/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1491/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1492/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1493/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1494/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1495/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1496/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1497/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1498/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1499/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1500/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1501/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1502/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1503/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1504/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1505/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1506/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1507/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1508/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1509/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1510/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1511/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1512/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1513/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1514/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1515/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1516/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1517/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1518/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1519/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1520/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1521/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1522/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1523/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1524/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1525/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1526/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1527/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1528/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1529/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1530/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1531/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1532/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1533/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1534/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1535/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1536/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1537/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1538/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1539/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1540/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1541/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1542/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1543/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1544/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1545/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1546/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1547/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1548/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1549/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1550/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1551/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1552/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1553/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1554/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1555/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1556/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1557/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1558/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1559/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1560/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1561/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1562/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1563/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1564/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1565/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1566/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1567/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1568/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1569/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1570/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1571/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1572/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1573/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1574/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1575/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1576/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1577/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1578/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1579/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1580/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1581/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1582/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1583/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1584/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1585/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0142, Val Acc: 0.7714\n",
      "Epoch 1586/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1587/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1588/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1589/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1590/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1591/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1592/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1593/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1594/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1595/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1596/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1597/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1598/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1599/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1600/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1601/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1602/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1603/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1604/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1605/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1606/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1607/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1608/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1609/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1610/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1611/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1612/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1613/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1614/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1615/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1616/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1617/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1618/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1619/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1620/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1621/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1622/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1623/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1624/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1625/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1626/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1627/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1628/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1629/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1630/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1631/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1632/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1633/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1634/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1635/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1636/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1637/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1638/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1639/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1640/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1641/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1642/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1643/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1644/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1645/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1646/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1647/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1648/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1649/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1650/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1651/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1652/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1653/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1654/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1655/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1656/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1657/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1658/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1659/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1660/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1661/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1662/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1663/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1664/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1665/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1666/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1667/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1668/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1669/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1670/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1671/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1672/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1673/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1674/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1675/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1676/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1677/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1678/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1679/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1680/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1681/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1682/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1683/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1684/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1685/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1686/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1687/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1688/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1689/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1690/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1691/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1692/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1693/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1694/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1695/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1696/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1697/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1698/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1699/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1700/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1701/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0143, Val Acc: 0.7714\n",
      "Epoch 1702/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1703/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1704/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1705/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1706/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1707/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1708/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1709/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1710/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1711/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1712/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1713/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1714/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1715/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1716/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1717/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1718/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1719/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1720/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1721/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1722/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1723/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1724/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1725/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1726/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1727/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1728/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1729/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1730/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1731/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1732/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1733/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1734/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1735/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1736/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1737/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1738/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1739/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1740/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1741/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1742/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1743/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1744/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1745/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1746/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1747/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1748/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1749/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1750/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1751/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1752/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1753/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1754/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1755/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1756/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1757/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1758/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1759/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1760/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1761/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1762/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1763/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1764/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1765/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1766/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1767/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1768/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1769/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1770/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1771/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1772/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1773/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1774/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1775/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1776/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1777/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1778/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1779/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1780/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1781/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1782/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1783/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1784/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1785/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1786/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1787/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1788/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1789/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1790/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1791/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1792/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1793/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1794/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1795/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1796/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1797/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1798/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1799/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1800/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1801/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1802/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1803/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1804/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0144, Val Acc: 0.7714\n",
      "Epoch 1805/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1806/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1807/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1808/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1809/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1810/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1811/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1812/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1813/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1814/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1815/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1816/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1817/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1818/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1819/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1820/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1821/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1822/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1823/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1824/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1825/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1826/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1827/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1828/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1829/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1830/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1831/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1832/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1833/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1834/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1835/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1836/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1837/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1838/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1839/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1840/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1841/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1842/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1843/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1844/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1845/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1846/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1847/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1848/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1849/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1850/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1851/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1852/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1853/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1854/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1855/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1856/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1857/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1858/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1859/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1860/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1861/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1862/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1863/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1864/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1865/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1866/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1867/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1868/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1869/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1870/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1871/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1872/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1873/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1874/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1875/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1876/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1877/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1878/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1879/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1880/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1881/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1882/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1883/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1884/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1885/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1886/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1887/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1888/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1889/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1890/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1891/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1892/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1893/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1894/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1895/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1896/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1897/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1898/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1899/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1900/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1901/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1902/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1903/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1904/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1905/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1906/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1907/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1908/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1909/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1910/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1911/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1912/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1913/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1914/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1915/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1916/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1917/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1918/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1919/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1920/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1921/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1922/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1923/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1924/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1925/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1926/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1927/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1928/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1929/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1930/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1931/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1932/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1933/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1934/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1935/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1936/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1937/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1938/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1939/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1940/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1941/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1942/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1943/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1944/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1945/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1946/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1947/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1948/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1949/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1950/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1951/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1952/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1953/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1954/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1955/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1956/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1957/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1958/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1959/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1960/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1961/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1962/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1963/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1964/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1965/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1966/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1967/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1968/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1969/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1970/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1971/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1972/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1973/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0145, Val Acc: 0.7714\n",
      "Epoch 1974/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1975/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1976/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1977/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1978/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1979/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1980/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1981/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1982/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1983/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1984/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1985/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1986/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1987/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1988/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1989/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1990/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1991/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1992/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1993/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1994/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1995/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1996/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1997/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1998/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 1999/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n",
      "Epoch 2000/2000: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 0.7714\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "history = np.zeros((0, 5), dtype=float)\n",
    "base_epochs = len(history)\n",
    "net.train()\n",
    "for epoch in range(base_epochs, num_epochs + base_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    for (x_l, y_l), x_u in zip(train_loader, unlabeled_loader):\n",
    "        # 全てGPUへ転送\n",
    "        x_l, y_l, x_u = x_l.to(device), y_l.to(device), x_u.to(device)\n",
    "        \n",
    "        # CPU上でPIL変換が必要なため、一旦CPUへ戻し変換後またGPUへ\n",
    "        x_weak_cpu = torch.stack([weak_transform(x_u[i].cpu()) for i in range(x_u.size(0))])\n",
    "        x_strong_cpu = torch.stack([strong_transform(x_u[i].cpu()) for i in range(x_u.size(0))])\n",
    "\n",
    "        # 変換後の画像をGPUへ戻す\n",
    "        x_weak = x_weak_cpu.to(device)\n",
    "        x_strong = x_strong_cpu.to(device)\n",
    "\n",
    "        # ラベルあり入力の損失計算\n",
    "        z_l = net(x_l)\n",
    "        loss_sup = ce(z_l, y_l)\n",
    "\n",
    "        # ラベルなし入力の疑似ラベル生成\n",
    "        with torch.no_grad():\n",
    "            z_ui = net(x_weak)\n",
    "            z_uj = net(x_strong)\n",
    "\n",
    "        loss_unsup = mse(z_ui, z_uj)\n",
    "\n",
    "        # 損失の合計\n",
    "        loss = loss_sup + lambda_u * loss_unsup\n",
    "        \n",
    "        # 逆伝播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # ラムダの更新\n",
    "    lambda_u = min(3, lambda_u + 0.001)\n",
    "\n",
    "    # 訓練データと検証データの損失と精度を計算\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = ce(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            train_acc += (preds == labels).sum().item()\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = ce(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            val_acc += (preds == labels).sum().item()\n",
    "\n",
    "    # 平均損失と精度の計算\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    avg_val_acc = val_acc / len(val_loader.dataset)\n",
    "\n",
    "    # エポック結果表示\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs+base_epochs}: \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}, \"\n",
    "        f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")\n",
    "\n",
    "    # 履歴更新\n",
    "    history = np.vstack((history, [epoch + 1, avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "721e4a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[初期状態] loss: 0.02576, accuracy: 0.21429\n",
      "[最終状態] loss: 0.01457, accuracy: 0.77143\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAycAAALLCAYAAADjWP3kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACPlElEQVR4nOzdeXxU1f3/8fdkTyaZEHbCjiwKgiIQVPY1X6FUWjcQVKqIoNIWtFisGpBNcS2iloICiiio1KWK7CGCRVEBcUEWAdkKBEImJJBMMvf3B7+5zTCTjYTcCfN6Ph7zILnLueczBJ13zjn32gzDMAQAAAAAFguxugMAAAAAIBFOAAAAAAQIwgkAAACAgEA4AQAAABAQCCcAAAAAAgLhBAAAAEBAIJwAAAAACAiEEwAAAAABgXACAAAAICAQTgAARVqwYIFsNpt69uxpdVdQwVavXi2bzaYHH3zQZ5/NZpPNZtO+ffsqv2MXID8/Xy1btlSdOnXkdDqt7g6AciCcAEARevbsKZvNpkmTJlndFaBCFRQUaPz48YqOjtbf/vY3q7tTbmFhYUpJSdGxY8c0ffp0q7sDoBwIJwCAIsXHx6tVq1Zq1KiR1V1BBVqwYIG2b9+u0aNHq169elZ3p0IMHTpUrVq10osvvqhff/3V6u4AuECEEwBAkX73u99px44deuONN6zuCirQCy+8IEm69957Le5JxQkJCdEf/vAH5ebm6pVXXrG6OwAuEOEEAIAgkpaWph9++EFJSUm64oorrO5OhRo+fLhCQkL0+uuvKy8vz+ruALgAhBMAqGBZWVmaPn26OnXqpPj4eEVFRally5YaN26c/vvf//o9Z+fOnXrqqafUq1cvNW7cWFFRUapWrZq6dOmil156SS6Xy+95I0aMMNfFnDp1Sg8//LBatGihqKgoXX311ZJ8F7UvWLBAnTt3VmxsrBwOh3r16qVVq1b5bb+4BfGFF01v375dt912m+rUqaPIyEi1atVKTz75ZLEfEL/55hvdeOONqlGjhmJiYtSuXTu98MILcrvd5nqfBQsWFHl+UfLz8/X666+rX79+qlWrliIjI9WgQQP16tVLs2bNUnZ2dqnq8yiqL4XPLSgo0KxZs9SxY0c5HA7ZbDYdPnzY/PqLL74osv0ffvhBNptNkZGROnnypNc+t9utRYsWqX///qpVq5YiIiJUv359DR06VFu2bCnzeyNJixYtkiTdeOONF3S+YRh6++231a9fP9WoUUMRERFq0KCBhg0bVmyf1q9fr5tuukn169dXRESEqlWrppYtW+rmm2/W/PnzfY7fu3evRo8erRYtWig6Olp2u11NmjRR3759NX36dK+/R4/69eurQ4cOOn78uD777LMLqg+AxQwAgF89evQwJBkpKSmlPuenn34ymjRpYkgyQkNDjaZNmxpt27Y1IiMjDUlGnTp1jG3btvmcd9NNNxmSjNjYWKN58+ZGp06djMaNGxuSDElG7969jby8PJ/z7rrrLkOS8cADDxjNmjUzbDab0bp1a6N9+/ZG586dDcMwjPnz5xuSjB49ehh33323Iclo2LCh0b59e8NutxuSjJCQEOODDz7wab/wuefz9G3OnDlGVFSUERsba3To0MFITEw09910001+36cPPvjACA8PN2vu2LGj0bRpU/Mcz3s/f/78Ur/3hmEYx44dM6699lrz+omJiUanTp2Mhg0bGiEhIYYkY8uWLaWqz6OovnjO7d69u3HjjTcakozGjRsbnTp1MhISEoyMjAxjxIgRhiTjvvvuK7L9CRMmGJKM3/3ud17bnU6n0bdvX7OWunXrGu3btzccDochyQgLCzMWLVpUpvfHMAzjsssuMyQZa9asKfIYzzX37t3rtd3lchk333yzub9BgwZGx44djfj4ePNnft68eT7tvf7664bNZjMkGdWqVTOuuuoqo127dkZCQoIhyahfv77X8Vu3bjXbjIqKMlq3bm106NDBqFu3rvn3uGvXLr99Hzt2rCHJ+POf/1zm9waA9QgnAFCEsoaTrKws84PfbbfdZhw6dMjcl5mZaQaJFi1a+ASNDz74wPjyyy8Nt9vttf2nn34yP2zPnDnT55qeNkNDQ41rrrnG2L17t7kvJyfHMIz/fYgODw83atSoYaxcudI85vTp0+YH6yZNmvhcvzThJDw83JgwYYJx5swZc98bb7xhfhhdu3at13lHjhwxP3iOGDHCOH36tLlv5cqVhsPhMINLWcKJ2+02unfvboaE1NRUr/0nTpwwXnzxRa8P3BURTkJDQ43q1asbq1evNvfl5uYaBQUFxtq1aw1JRkJCgnH27FmftgsKCowGDRoYkox//etfXvtuvfVWQ5LRvn17Y/PmzV7nvPjii0ZISIgRGRlp7Nixo+Q35/87dOiQ+feWmZlZ5HFFhZNJkyYZkoyYmBhj2bJl5vazZ88a48aNM0NT4f7m5+cbNWrUMCQZs2bNMlwul1ebP/30k/H3v//da9vgwYMNScbw4cN9+nns2DFj9uzZxtGjR/32fdGiRYYk45prrin2vQAQmAgnAFCEsoaTp59+2pBkdOnSxcjPz/fZn5+fb7Rv396QZLz99tul7seuXbsMScYVV1zhs88TTiIiIoz9+/f7Pd/zIVqS8eabb/rsP3z4sBkGzh/VKU046dOnj9/rDhw40JBkjBs3zmt7SkqKIcm48sor/b5Pc+fONdsuSzj56KOPzN+0//zzz6U6pyLCiSTjnXfe8Xuu2+02GjVqZEgy3nvvPZ/9q1atMiQZNWrU8AqsX375pSHJqF69ulfILcwzQlDcqMz5NmzYYI5WFcdfODl9+rQ5avPMM8/4Pa9bt26GJGPw4MHmtiNHjpgjJqXVqlUrQ5KxdevWUp/jsW7dOjMQAqh6WHMCABXk3XfflSSNHDlSoaGhPvtDQ0PNef5r16712X/s2DHNmjVLw4cPV79+/dStWzd17dpVI0aMkCTt2LFDZ86c8Xvtvn37lni73/j4eA0bNsxne7169dS0aVNJ0u7du4ttw58HHnjA7/YuXbr4bXP58uWSzq2X8fc+DRs2TFFRUWXux3vvvSdJuuWWW9SyZcsyn3+hHA6HbrrpJr/7bDabhg8fLkl68803ffZ7tg0ZMkTh4eHmds/P0qBBg5SYmOi3bc81/f0sFeX48eOSpOrVq5f6HI/PP/9cTqdTMTExGjNmjN9jHn74YUnSypUrlZ+fL0mqVauWoqKidOrUKX300UelupbnZ/mtt95SQUFBmfrpqe3UqVNmHwBUHWFWdwAALhXbtm2TdO42rfPmzfN7zNGjRyVJBw8e9Nr+3nvv6Q9/+INOnz5dZPuGYejkyZOqX7++z77WrVuX2L8WLVrIZrP53VenTh3t3Lmz2OsXpaggUKdOHUnyafPnn3+WJF111VV+z4uOjlbLli313Xfflakf33//vSTp+uuvL9N55dWyZUuFhRX9v9O77rpL06dP16effqoTJ06oRo0akqTs7GwtW7ZMknTnnXd6neP5WUpNTVXXrl39tnv27FlJvj9LxfGE2wsJf56/t2bNmslut/s9pm3btpKknJwc/frrr2rWrJlCQ0P10EMPadq0abrxxhvVunVr9evXT0lJSerZs6ff8PXwww9r9erVeuaZZ/Tmm28qOTlZ1157rbp166Y2bdoU209PbYZh6OzZs4qNjS1zrQCsQzgBgAqQnZ1t3lGrNB+qc3JyzK/37dun4cOHKzc3V7feeqv++Mc/6vLLL1d8fLzCwsLkdrvNEYai7tpV1IfF0h4TEnJuIN3tdpfYTmnbLapNT1iJi4srss3i9hXF6XRKkqpVq1bmc8ujpPe+ZcuW6ty5s7788ku988475kjTv/71L50+fVqXX365kpKSvM7JyMiQJO3fv1/79+8vtv2iRtP8qVmzpiT53BWsNLKysiRJdevWLfKYwg909BwvSVOmTFGjRo308ssv67vvvtOPP/4o6dzIUp8+ffTcc8+pXbt25vH9+/fXmjVrNH36dK1fv14LFy7UwoULJUlXXHGFpk2bpt/97nd+++CpLTIykmACVEFM6wKAChATE2MGiK1bt8o4t6avyFdqaqp57jvvvKPc3Fx17txZb7/9trp06aIaNWqYv40/ceKEFSVdNJ4PjIU/vJ6vuH1FcTgcks5N5yktz0iSYRhFHuPvlrVl5RkZKfwwS8/X54+aSP97j1588cUSf5aK6/v5PKNZGRkZZQ6insBY1O2wJenIkSM+x0vn3udRo0Zp27ZtOnbsmJYtW6axY8eqVq1aWr16tXr37q3Dhw97teW5xfWpU6e0Zs0apaSkqE2bNvrpp5900003acWKFX774AkntWvXLlN9AAID4QQAKoDNZjOnVm3cuLFM5+7du1fSuTUantGGwop7RkZV1KpVK0n/m7p0vrNnz2rnzp1lbtczpags75dn1MMz3c6fXbt2lbkv5xsyZIgiIiL01VdfaefOnTpy5IjWrFmjkJAQc01KYZ5ayvqzVJIrrrhCMTExKigo0I4dO8p07uWXXy5J+uWXX7xG/grzTK2LiYkpcg1UrVq19Lvf/U6zZs3Srl271KRJE504cUJLly71e3xMTIx69+6tSZMmafv27brppptkGIZeffVVv8dv375dktSxY8cy1QcgMBBOAKCC3HrrrZLOrTkpy2/bY2JiJMnnN8fSud/oP/vssxXTwQDxf//3f5LOPcTQ32Lnt956y1xPURY333yzpHOLyUu7sL9FixaSzgVEfwHlrbfeUmZmZpn7cr7q1atr4MCBks6NmCxatMh82GTDhg19jvf8LH3wwQfmB/6KEB4ebq7J2bRpU5nO7dq1qxwOh3JycjRnzhy/xzz33HOSpOTk5GLX4Xg4HA5z7ZG/n//z2Ww2cw1OUcd76iruwZoAAhfhBAAqyB//+Edddtll2r17t/r16+ez9sQwDH3zzTcaN26cNm/ebG7v0aOHpHOL4gvfzSgrK0t33323vv7668opoJKMHj1a8fHx+v7773Xvvfd6BbnVq1dr/PjxXneuKq2BAweqZ8+eOnv2rJKTk/X555977c/IyNCsWbO81nC0bdtWTZo0UV5enh588EGvEYE1a9boz3/+8wX1xR/P9K1FixYVO6VLOhcEbrnlFrlcLiUnJ+vjjz/2mb61b98+PfPMM3rttdfK1A9PSCo8tbA07Ha7xo8fL0l64oknvH5Wc3NzNWHCBK1fv15hYWF69NFHzX0//vij7rnnHm3YsMFnKtmqVau0Zs0aSVKnTp3M7bfccouWLVvmM0KzZ88e/fOf//Q53qOgoMAcbbrhhhvKVB+AAFF5dy0GgKrF83yL6Ohoo0aNGkW+evbsaZ6za9cu4/LLLzefE9GwYUOjc+fOxlVXXWXExcWZ29etW2eeU1BQYPTs2dPc16RJE6NDhw5GTEyMERISYrzxxhtFPhTP85yT4p7FUhHP8ijuOSfn96k0537wwQdGWFiY+cyNTp06Gc2aNTMkGb///e/Nhym+8cYbRfbZn6NHjxpJSUlm3+rXr2906tTJaNSokd8nxBuGYfzrX/8y98XGxhrXXHON+WySu++++4LeG3/y8vKMmjVrmn2z2+1GVlZWkcdnZ2cbv/3tb83jq1evbnTq1Mno0KGDUadOHXN7aZ/D43HixAkjKirKiIuLM7Kzs/0eU9TfrcvlMm666SZzf6NGjYxOnTp5PSF+7ty5Xuds2bLFPD4mJsZo166d0alTJyMxMdHcPnjwYK8HgHraCwsLM1q1amV07tzZaNGihflgzxYtWvh9COOnn35a7LN3AAQ+Rk4AoARnzpzRiRMninx57qwkSc2bN9eWLVv08ssvq1evXsrJydG3336ro0ePqmXLlnrggQe0atUqr9vDhoSE6JNPPtFf//pXNW3aVIcOHdKvv/6qXr16ae3atbrjjjusKPuiuvHGG/Wf//xHgwYNUnh4uLZv367o6Gg988wzWrp0qTma4lnkXlq1a9fWhg0bNGfOHPXo0UM5OTnaunWrOYXqpZde8rn18eDBg/XZZ5+ZI1g7duxQrVq1NHfu3DKPShQnPDxcQ4YMMb//3e9+V+zdpGJiYvTBBx/oo48+0u9+9ztFRUVp27Zt2rt3r2rVqqWhQ4fq7bffNkczSqt69eoaMmSIsrKyzFsZl1ZYWJjeffddvfXWW+rdu7eysrK0detW2e12DR06VF999ZVGjhzpdU7Lli312muv6fbbb1ejRo104MABbdmyRXl5eerbt6/eeOMNvf/++163uX7jjTf0wAMPqG3btsrIyNA333yjo0ePqmPHjpo2bZq+/fZbvwvePc+NKeo5LAACn80wynCbDwAALrKCggJVr15dTqdT27Zt87rFLCrG7t271aZNG7Vp00bffPNNkc+/qUr279+vli1bqnXr1vrmm2/83lwCQODjXy4AIKAsXbpUTqdTNWrUKNXDJVF2zZs314MPPqgtW7bo/ffft7o7FeLJJ59UXl6enn/+eYIJUIXxEEYAQKX75JNPlJ2drRtvvFGRkZGSzt0w4IMPPtD9998v6dzUnNLc8QkX5vHHH5fD4VBubq7VXSm3goICNWvWzJxOCaDqYloXAKDSvfjiixo3bpzCwsLUpEkTJSQkaO/evUpPT5d07gF8y5cvN4MLACA4EE4AAJXuxx9/1CuvvKL169fryJEjyszMVFxcnNq2bauhQ4fqnnvuqbBb+AIAqg7CCQAAAICAwIoxAAAAAAGBlYYBxO126/Dhw4qLi7skbusIAAAASOduepKVlaXExMRi76hHOAkghw8fVsOGDa3uBgAAAHBRHDhwQA0aNChyP+EkgMTFxUk695dW1qcil5fL5dLKlSvVv3//oFyEGsz1B3PtUnDXH8y1S8FdfzDXLgV3/dQenLVL1tfvdDrVsGFD8/NuUQgnAcQzlcvhcFgSTmJiYuRwOIL2H2yw1h/MtUvBXX8w1y4Fd/3BXLsU3PVTe3DWLgVO/SUtXWBBPAAAAICAQDgBAAAAEBAIJwAAAAACAuEEAAAAQEAgnAAAAAAICNytCwAAoApyuVwqKCgo8zlhYWE6e/Zsmc+t6oK5dqni6w8NDb0od/0inAAAAFQhTqdT6enpys3NLfO5hmGobt26OnDgQIm3dL3UBHPt0sWpPzIyUjVr1qzQR2AQTgAAAKoIp9OpQ4cOKTY2VjVr1lR4eHiZPmi63W6dPn1asbGxCgkJrtn9wVy7VLH1G4Yhl8ulzMxMHTp0SJIqLKAQTgAAAKqI9PR0xcbGqkGDBhf022+32628vDxFRUUF3Qf0YK5dqvj6o6OjFRcXp4MHDyo9Pb3Cwknw/c0AAABUQS6XS7m5uYqPjw/KaUkIPDabTfHx8crNzZXL5aqQNgknAAAAVYBnEfPFWIQMXCjPz2NF3WSAcAIAAFCFMGqCQFLRP4+EEwAAAAABgXACAAAAICAQTgAAAAAEBMIJAAAAcJ5JkybJZrMpNTW1XO307NmTdUJlQDgBAABAlZCamiqbzaZJkyZZ3RVcJDyEEQAAADjPgw8+qCFDhqhRo0blaueNN95QTk5OBfXq0kc4AQAAAM5Ts2ZN1axZs9ztlDfcBBumdQEAACDgTZo0Sb169ZIkTZ48WTabzXzt27dPI0aMkM1m0y+//KIXXnhBbdq0UWRkpEaMGCFJOnz4sGbMmKHrr79etWvXVmRkpJo0aaL7779fx44d83u989ec7Nu3TzabTSNGjNAvv/yim2++WQkJCbLb7erbt6+2bdvm046/NScLFiyQzWbTggULtGbNGnXt2lV2u101atTQXXfdpRMnTvh9D+bMmaM2bdooKipKDRs21IQJE3T27FnZbDb17Nnzwt7YAMPICQAAQBVnGFJpZg653VJ2thQaKoVU8q+oY2Kk8qwL79mzp/bt26eFCxeqR48eXh/Gq1WrZn49duxYbdq0SQMHDtRvfvMb1alTR5KUlpaml19+Wb1791bnzp0VHh6uLVu26NVXX9WKFSv07bffKj4+vlR92bdvnzp37qzWrVvr7rvv1p49e/Thhx+qV69e+umnn8xrluTjjz/Wv//9bw0aNEhjxoxRWlqa3njjDe3Zs0cbNmzwOvaJJ57QlClTVK9ePY0aNUphYWF69913tWPHjlJdq6ognAAAAFRxOTlSbGxpjgyRVO3idqYIp09LdvuFn+8JIwsXLlTPnj2LXBT/3XffacuWLT7TqXr37q0dO3YoMTFRIYWS2RtvvKG77rpLs2fP1t/+9rdS9WX9+vV66qmn9Mgjj5jbHn/8cU2dOlXz58/XX//611K189FHHyk1NVVdunSRJBUUFKhv375KTU3Vpk2bdO2110qSdu7cqenTp6tRo0b69ttvVaNGDUnSk08+aR5zqWBaFwAAAC4Zf/nLX/yu86hdu7Zi/SS4O+64Qw6HQ6tXry71NZo2baq//OUvXtvuueceSdLmzZtL3c7tt99uBhNJCg0N1V133eXTzttvv62CggI99NBDZjCRpNjYWD322GOlvl5VwMgJfOzevVuRkZFq2LCh1V0BAAClEBNzbmSiJG63W06nUw6Hw2v0oDLExFTOdZKSkorc9/HHH+vNN9/Uli1blJGRoYKCAnPf4cOHS32Nq666yuf9a9CggSTp1KlTpW7nmmuu8dnmrx3PWpbrr7/e53h/26oywgm8nDp1Si1atJAkGYZhcW8AAEBp2GylmzLldksFBeeOrew1J5WlqPUezz//vP7yl7+oVq1a6t+/vxo0aKDo6GhJ0osvvqjc3NxSX8Pf2pSwsHMfqwsHnopqx+l0SpJq1arlc3xp17dUFYQTeNm/f7/VXQAAALhg/p7Gnp+fr6lTp6pevXrasmWL1wd6wzA0c+bMyuximTkcDknS8ePH1bhxY699R48etaJLF80lmpkBAABwqQkNDZVUttEJSUpPT1dmZqY6duzoM/rw9ddf68yZMxXWx4vhqquukiR98cUXPvv8bavKCCcAAACoEqpXry5JOnjwYJnOq127tqKjo7Vt2zavp7VnZGRo7NixFdrHi2HIkCEKCQnR888/7/UMlOzsbE2bNs3CnlU8pnUBAACgSrj88suVmJiod955RzExMWrQoIFsNpvGjBlT7HkhISEaM2aMnn/+ebVv316DBg2S0+nU8uXL1bhxYyUmJlZSBRemVatW+utf/6rp06erbdu2uuWWWxQWFqZly5apbdu2+v777yv9BgcXC+EEAAAAVUJoaKiWLVumRx55RG+++aaysrIknRtZKMn06dMVExOjJUuW6JVXXlGdOnU0ZMgQTZ48WVdeeeXF7nq5TZs2TQ0aNNBLL72kf/zjH6pdu7aGDBmiP/3pT/r444/NdSlVHeEEAAAAVUbnzp2Vmprqs33BggVasGBBkeeFh4froYce0uTJk31GGfbt2+dz/KRJk3we9NikSZNi72bqb5+/vo4YMUIjRozw20bPnj2LvMaYMWN8Rok8z2dp1apVkf2qSi6N8R8AAADgEnb8+HGfGwGcOnVKEydOlCQNHjzYgl5VPEZOUCTDMPzejg8AAACV66233tKzzz6r3r17KzExUUeOHNFnn32mY8eOacSIEbruuuus7mKFIJwAAAAAAe76669Xhw4dtHr1ap08eVKhoaG64oor9Pjjj+v++++3unsVhnACAAAABLikpCR9+OGHVnfjomPNCQAAAICAQDhBkYq7GwUAAABQ0QgnAAAAAAIC4QQAAABAQCCcAAAAAAgIhBMUiTUnAAAAqEyEEwAAAAABgXACAAAAICAQTgAAAAAEBMIJisSaEwAAECx69uwpm83mtS01NVU2m02TJk0qVzsVrUmTJmrSpMlFvYZVCCcAAABAABkxYoRsNpv27dtndVcqXZjVHQAAAAACUVJSkn766SfVrFnT6q54WbNmjdVduGgIJwAAAIAfMTExuvzyy63uho/LLrvM6i5cNEzrQpFYcwIAAAJFWlqabDab7rnnHr/7Dx48qNDQUPXp00eS9M033+jBBx/UlVdeqfj4eNntdl1//fV6+umn5XK5SnXN4tacbNiwQT169JDdbleNGjV022236cCBA37bOXz4sFJSUnTttdeqdu3aioyMVJMmTXT//ffr2LFjXsc2adJECxculCQ1bdpUNptNNptNPXv29DrG35qTnJwcTZo0SZdffrmioqJUvXp1DRw4UF988YXPsZMmTZLNZlNqaqqWLl2qa665RtHR0apXr57++Mc/6syZM6V6jyoaIycAAABVnGEYysnJKfE4t9ut7OxshYaGKiSkcn9HHRMTU66F4t26dVOTJk30/vvv6+WXX1ZUVJTX/rfeektut1t33HGHJGnu3Ln6+OOP1b17dw0YMEDZ2dlau3atHn30UX399dd6//33L7gva9as0Q033KCQkBDddtttSkxM1Jo1a9SlSxclJCT4HJ+WlqbnnntOffr0UefOnRUeHq4tW7bo1Vdf1YoVK/Ttt98qPj5ekvTnP/9ZCxYs0LZt2/SnP/1J1apVk6QSF8Dn5uaqT58+2rRpk6655hr9+c9/1rFjx7RkyRKtXLlSb7/9tvr27etz3ssvv6zly5frxhtvVM+ePfXZZ5/ppZde0okTJ/TWW29d8Ht0oQgnAAAAVVxOTo5iY2Ot7kaxTp8+LbvdfsHn22w2DRs2TNOmTdPHH3+sW265xWv/W2+9pejoaN10002SpIkTJ+rll19WaGiopHPBLDMzUw899JDmz5+vjRs3qkuXLmXuh9vt1qhRo5Sfn6+0tDR17dpV0rmAOHz4cC1evNjnnN69e+u///2vz9/RG2+8obvuukuzZ8/W3/72N0nnwsnWrVu1bds2/fnPfy71XblmzpypTZs2adiwYXrzzTfNIPjnP/9ZSUlJGjVqlLZt2yaHw+F13qpVq/TNN9+oVatWkqRp06bp6quv1ttvv61nnnlGiYmJZXp/yotpXQAAAKgSPKMiixYt8tq+bds2bd++XTfeeKPi4uIkSY0bNzaDiYfNZtP9998vSVq9evUF9WHDhg365Zdf9Jvf/MYMJp62p0+f7nNNSapdu7bf8HjHHXfI4XBccF8KW7BggcLDw/XUU095jVC1a9dOI0aMUEZGhj799FOf8/70pz+ZwUSSoqOjNXToUBmGoW+++abc/SorRk5QJNacAABQNcTExOj06dMlHud2u+V0OuVwOCyZ1lVerVq1UseOHbV8+XKdPHlS1atXlyS9+eabkv4XXiQpLy9Ps2fP1jvvvKMdO3bo9OnTXp9tDh8+fEF92LZtm6Rz08zO17hxYzVs2NDvLYCXLVumOXPm6Ntvv1VGRoYKCgrK3RcPp9OpX375RVdccYUaNGjgs79nz56aM2eOvv/+e59911xzjc82TxunTp0qV78uBOEEAACgirPZbKWaMuV2u1VQUCC73V7p4aSi3HHHHfr666+1dOlSjR49Wm63W2+//bZq166t/v37m8fdfPPN+vjjj9WyZUvddtttqlWrltxut86cOaNZs2YpNzf3gq6fmZkp6dxoiD916tTxCSfPPfecHn74YdWqVUv9+/dXgwYNFB0dLUl68cUXL7gvHk6n07y2P3Xr1vU6rjDPWpfCwsLORYTCAaqyEE4AAABQZQwZMkQPPfSQFi1apNGjR2vt2rU6fPiw/vSnP5kfqjdv3qyPP/5YycnJ+uSTTxQaGmqOGv3444+aNWvWBV/f82H+/LtseRw9etTr+/z8fE2ZMkWJiYnaunWratWqZe4zDEMzZ8684L54eNaRnH/t8/vkmfIWyKpmZAYAAEBQ8oyQfPHFF9q7d6+5/mT48OHmMXv27JEkDRw40GcNyIYNG8p1/auuukqS9Pnnn/vs279/v8/thNPT05WZmalrr73WK5hI0tdff+33lr2ePpd25MLhcKhZs2bavXu3Dh065LN//fr1kqQrr7yyVO1ZiXCCIrHmBAAABKI77rhDhmFo3rx5WrZsmS6//HJ17NjR3N+4cWNJvkHkp59+0lNPPVWua3ft2lVNmzbVv//9b6/2DcPQo48+6hMoateurejoaH377bdet3vOyMjQ2LFj/V7Ds5bm4MGDpe7XXXfdJZfLpYkTJ3p9hvv+++81f/58xcfHa+DAgaVuzypM6wIAAECVcuONN8rhcOiZZ56Ry+XyWggvSUlJSUpKStLSpUt15MgRXXvttdq/f78+/vhjDRgwoFzPOAkJCdE///lPDRgwQH379jWfc7J27VodOXJE7dq103fffed1/P3336/nnntOV111lQYNGiSn06nly5ercePGfm/V27t3bz377LO67777dMstt8hut6tRo0a6/fbbi+zXhAkT9Mknn+jNN9/UTz/9pD59+uj48eNasmSJXC6XFixYwLQuAAAAoKJ5nmficrnM558UFhoaqn//+9+6++67tWfPHr300kv66aef9OSTT+rpp58u9/X79u2rNWvWqHPnznr33Xf1z3/+U40bN9aGDRv8PoRxxowZmjZtmmw2m1555RWtWrVKQ4YM0cqVKxUeHu5z/A033KCZM2fK7Xbr6aef1sSJE/XPf/6z2D5FRUVp7dq1evzxx+V0OvXCCy9o2bJl6t69u1JTU32eCxOobAZzdwKG0+lUfHy8MjMzfR6Qc7G5XC59+umnql+/vjp16iRJOnv2rCIjIyu1H1bx1D9gwAC//5G4lAVz7VJw1x/MtUvBXX8w1y5V3frPnj2rvXv3qmnTpj5PRy8tK28lbLVgrl26ePWX9ueytJ9zg+9vBqVGbgUAAEBlIpzAS+EnigIAAACVKWDDyebNmzVgwAAlJCTIbrcrKSlJixcvLlMbbrdbs2fPVrt27RQdHa1atWrp1ltv1a5du3yOPXXqlP74xz/quuuuU926dRUZGan69eurd+/eev/994scRXA6nRo/frwaN26syMhINW7cWOPHj/f7kJuqgNESAAAAWCUgw0lqaqq6du2qzz//XDfffLPGjBmj9PR0DRs2TNOnTy91O6NHj9bYsWNVUFCgsWPHasCAAfroo4/UqVMn/fjjj17Hpqen6/XXX5fdbtfgwYP10EMP6YYbbtAPP/ygm2++Wffdd59P+9nZ2erRo4deeOEFtWrVSuPGjVPr1q31wgsvqEePHsrOzi73ewEAAAAEi4C7lXB+fr5Gjhwpm82mtLQ0tW/fXpKUkpKi6667TikpKbrlllvUokWLYttZt26d5s6dq27dumnVqlXmwu4777xT/fr105gxY8wH0khS06ZNderUKfPJoh5ZWVm69tprNXfuXP3pT39SmzZtzH0zZ87U1q1bNWHCBK87P6SkpOjJJ5/UzJkzNXny5HK/J1ZhFAUAAACVKeBGTtauXas9e/bo9ttvN4OJJMXFxenxxx9Xfn6+5s+fX2I7c+fOlSRNnTrV645Tffr0UXJystLS0rRz505ze2hoqE8w8Vw3OTlZkrR7925zu+fBP7GxsXriiSe8zpk4caISEhL02muvVbkP+Kw5AQAAgFUCLpykpqZKkvr37++zz7Ot8IhHce3Y7XZ16dLFZ58nbJSmnbNnz2rt2rWy2Wxq3bq1uX3Xrl06fPiwunTpIrvd7nVOVFSUunfvrkOHDnkFmqqgqoUpAACCDf+vRiCp6J/HgJvW5Vms7m/aVkJCgmrWrOl3QXth2dnZOnLkiK688kqFhob67Pe0XdTC+BdffFFut1vHjh3Tp59+qgMHDiglJcWrT8X18/xrFHVMbm6ucnNzze89i+hdLpdcLlexNVY0z/Xy8/PNbXl5eX5Hky5Fnvor+30PBMFcuxTc9Qdz7VJw1x/MtUtVt37DMGQYhvLy8i74OWSeD5KGYcjtdldk9wJeMNcuXbz6c3NzzZ/N4v5NlfbfW8B98szMzJQkxcfH+93vcDh08ODBcrdR+LjCTp065bVOJDw8XM8884weeuihCruGx4wZM/yuSVm5cqViYmKKPO9i+vLLL82vV6xYETQPYfRYtWqV1V2wTDDXLgV3/cFcuxTc9Qdz7VLVrL9mzZoKDw+X2+0u11TsrKysCuxV1RLMtUsVW79hGEpPT9fJkydLHDzIyckpVZsBF06s1qRJExmGoYKCAh04cEDvvPOO/va3v+mLL77Q0qVLK3QkYeLEiRo/frz5vdPpVMOGDdW/f39LnhC/atUqXXvttea25ORky0JSZfPU369fvyr1tOCKEMy1S8FdfzDXLgV3/cFcu1S168/KytJ///tfZWVlyeFwKDw8vEwhxTAMZWdny263B90602CuXarY+j2jJFlZWXK5XGrdurXi4uKKPae0j9kIuHDiGYkoasTB6XQWOVpRljYKH+dPaGiomjRpor/+9a8KDQ3VhAkTNHfuXI0ZM6bCrhEZGel3ZCI8PNyy/1gWngZnZT+sEow1ewRz7VJw1x/MtUvBXX8w1y5VzfqrV6+usLAwpaen68iRI2U+3zAMnTlzRtHR0UH3AT2Ya5cuTv2RkZFq0KBBqX6pXtp/awEXTgqv1ejQoYPXvoyMDKWnp+v6668vtg273a569epp7969Kigo8Fl3UtJ6kfP1799fEyZMUGpqqhlOilu3ciHXCEQsuAMAIPA4HA45HA65XC4VFBSU6VyXy6W0tDR17969ygWz8grm2qWKrz80NPSivI8BF0569OihGTNmaOXKlRoyZIjXvpUrV5rHlKadd955Rxs3blT37t299q1YsaLU7UjS4cOHJclrSleLFi2UmJiojRs3mkNkHmfPnlVaWpoSExPVvHnzUl0jUATjbxIAAKiKLmTkJzQ0VPn5+YqKigq6D+jBXLtUdeoPuFsJ9+nTR82aNdPixYu1detWc3tWVpamTJmisLAwjRgxwtyenp6uHTt2KD093audUaNGSZIee+wx5eXlmdvXrFmjFStWqHv37mrZsqW5fevWrX6naJ08eVKPPvqoJOmGG24wt9tsNo0cOVKnT5/Wk08+6XXOjBkzlJGRYT5MEgAAAEDJAm7kJCwsTPPmzVNycrK6deumoUOHyuFwaNmyZdq7d6+mTp3qFSpmz56tyZMnKyUlRZMmTTK39+rVSyNHjtS8efPUvn17DRw4UEePHtWSJUvkcDj06quvel13wYIFmjdvnnr16qXGjRvLbrdr//79+uSTT3T69GnddNNNuv32273OmTBhgj766CPNnDlTW7ZsUYcOHbRt2zYtX75cV199tSZMmHBR36uLgalcAAAAsErAhRPpXLDYsGGDUlJStHTpUuXl5alNmzaaMmWKhg0bVup25syZo3bt2mnOnDmaNWuWYmNjNWjQIE2bNs0r4EjSzTffrMzMTG3atElpaWnKyclR9erV1bVrV915550aMmSIzyiI3W5XamqqJk+erPfee0+pqamqW7euxo0bp5SUFJ+HM1Y1BBUAAABUpoAMJ5KUlJSk5cuXl3jcpEmTvEZMCgsJCdHYsWM1duzYEtvp2rWrunbtWtZuKj4+Xs8//7yef/75Mp8biJiGBgAAAKsE3JoTAAAAAMGJcAIvTOUCAACAVQgnKBJBBQAAAJWJcAIvrDkBAACAVQgnAAAAAAIC4QRemMoFAAAAqxBOUCSCCgAAACoT4QReWHMCAAAAqxBOAAAAAAQEwgkAAACAgEA4QZFYcwIAAIDKRDgBAAAAEBAIJwAAAAACAuEEAAAAQEAgnKBIrDkBAABAZSKcAAAAAAgIhBMAAAAAAYFwAgAAACAgEE5QJNacAAAAoDIRTgAAAAAEBMIJAAAAgIBAOAEAAAAQEAgnKBJrTgAAAFCZCCcAAAAAAgLhBAAAAEBAIJwAAAAACAiEExSJNScAAACoTIQTAAAAAAGBcAIAAAAgIBBOAAAAAAQEwgmKxJoTAAAAVCbCCQAAAICAQDgBAAAAEBAIJwAAAAACAuEERWLNCQAAACoT4QQAAABAQCCcAAAAAAgIhBMAAAAAAYFwgiKx5gQAAACViXACAAAAICAQTgAAAAAEBMIJisS0LgAAAFQmwgkAAACAgEA4gRdGSwAAAGAVwgkAAACAgEA4QZEYRQEAAEBlIpwAAAAACAiEE3hhtAQAAABWIZwAAAAACAiEExSJURQAAABUJsIJAAAAgIBAOIEXRksAAABgFcIJAAAAgIBAOEGRGEUBAABAZSKcAAAAAAgIhBMAAAAAAYFwAgAAACAgEE5QJNacAAAAoDIRTgAAAAAEBMIJvDBaAgAAAKsQTgAAAAAEBMIJisQoCgAAACoT4QSSpPz8fJ05c0bZ2dlWdwUAAABBKszqDiAwfPLJJxo6dKgiIiKs7goAAACCFCMnkCTZbDZJktvttrgnAAAACFaEE0j6XzgpvM6ENScAAACoTIQTSJK++ebcj0JBAYEEAAAA1iCcQJLkdnt+FAgnAAAAsAbhBJL+N62LcAIAAACrEE4gqXA4+R/WnAAAAKAyEU4gyX84AQAAACpTwIaTzZs3a8CAAUpISJDdbldSUpIWL15cpjbcbrdmz56tdu3aKTo6WrVq1dKtt96qXbt2+Rx76NAhvfjii+rfv78aNWqkiIgI1a1bVzfddJO+/PJLv+1PmjRJNpvN7ysqKuqC6rYK4QQAAABWC8iHMKampio5OVkREREaMmSI4uPjtWzZMg0bNkz79u3To48+Wqp2Ro8erblz56p169YaO3asjh49qiVLlmjlypX64osv1Lp1a/PYl156SU8//bQuu+wy9evXT7Vr19auXbv0wQcf6IMPPtDbb7+tW2+91e917rrrLjVp0sRrW1hYQL61RQoJCdicCgAAgCARcJ+g8/PzNXLkSNlsNqWlpal9+/aSpJSUFF133XVKSUnRLbfcohYtWhTbzrp16zR37lx169ZNq1atUmRkpCTpzjvvVL9+/TRmzBitX7/ePD4pKUlpaWnq1q2bVzuff/65+vTpozFjxujGG2802ylsxIgR6tmzZzkrtxZrTgAAAGC1gPt1+dq1a7Vnzx7dfvvtZjCRpLi4OD3++OPKz8/X/PnzS2xn7ty5kqSpU6d6BYo+ffooOTlZaWlp2rlzp7n997//vU8wkaRu3bqpV69eOnnypLZv316e0gIa07oAAABgtYAbOUlNTZUk9e/f32efZ1vhEY/i2rHb7erSpYvPvuTkZH322Wdav369WrZsWWJb4eHhkoqeqvX555/rq6++UmhoqC6//HL17dvX7whLICOcAAAAwGoBF048i9X9TdtKSEhQzZo1/S5oLyw7O1tHjhzRlVdeqdDQUJ/9nrZLakeSfv31V61evVp169ZV27Zt/R7zxBNPeH1fr149LVy4UP369Su27dzcXOXm5prfO51OSZLL5ZLL5SqxbxXJMNw+26zoh1U8dQZLvYUFc+1ScNcfzLVLwV1/MNcuBXf91B6ctUvW11/a6wZcOMnMzJQkxcfH+93vcDh08ODBcrdR+LiiuFwu3XHHHcrNzdXMmTN9gs7VV1+thQsXqkePHqpTp44OHjyod955R9OnT9dvf/tbbdq0SVdddVWR7c+YMUOTJ0/22b5y5UrFxMQU27eKtmfPIZ9ta9euVZ06dSq1H1ZbtWqV1V2wTDDXLgV3/cFcuxTc9Qdz7VJw10/twcuq+nNyckp1XMCFk0Dhdrt19913Ky0tTffee6/uuOMOn2MGDx7s9X3z5s312GOPqU6dOho1apSmTp2qd999t8hrTJw4UePHjze/dzqdatiwofr3728GqMry3Xe+U+V69erlcxeyS5XL5dKqVavUr18/cxpfsAjm2qXgrj+Ya5eCu/5grl0K7vqpPThrl6yv3zNDqCQBF048ox1FjWo4nc4iR0TK0kbh485nGIbuvfdeLVq0SMOHD9c//vGPUvXd46677tL999+vjRs3FntcZGSk37Up4eHhlf5D4289jRX9sFow1uwRzLVLwV1/MNcuBXf9wVy7FNz1U3tw1i5ZV39prxlwd+sqbj1IRkaG0tPTS7yNsN1uV7169bR3714VFBT47C9uXYvb7dY999yj119/XUOHDtWCBQvK/AyQiIgIxcXFlXr4KhCwHh4AAABWC7hw0qNHD0nn1l2cz7PNc0xJ7WRnZ/sdvVixYoXfdtxut0aOHKn58+frtttu05tvvul3QX1Jdu3apYyMjCo1JYrnnAAAAMBqARdO+vTpo2bNmmnx4sXaunWruT0rK0tTpkxRWFiYRowYYW5PT0/Xjh07lJ6e7tXOqFGjJEmPPfaY8vLyzO1r1qzRihUr1L17d6/bCHtGTObPn69bbrlFixYtKjaYZGVl6bvvvvPZnpGRoXvuuUeSNHTo0DLVbiWeEA8AAACrBdyak7CwMM2bN0/Jycnq1q2bhg4dKofDoWXLlmnv3r2aOnWqV6iYPXu2Jk+erJSUFE2aNMnc3qtXL40cOVLz5s1T+/btNXDgQB09elRLliyRw+HQq6++6nXdJ598UgsWLFBsbKxatmypqVOn+vRt8ODBuvrqqyVJJ06c0FVXXaWOHTuqbdu2ql27tg4dOqTly5frxIkT6tevn8aNG3dR3qOLgeecAAAAwGoBF06kc8Fiw4YNSklJ0dKlS5WXl6c2bdpoypQpGjZsWKnbmTNnjtq1a6c5c+Zo1qxZio2N1aBBgzRt2jSfhy/u27dPknT69GlNmzbNb3tNmjQxw0n16tX1wAMPaNOmTfr444916tQp2e12tW3bVsOHD9fIkSMvaEqYVQgnAAAAsFpAhhNJSkpK0vLly0s8btKkSV4jJoWFhIRo7NixGjt2bIntLFiwQAsWLCh1/xwOh2bPnl3q4wMda04AAABgNRYaQBJrTgAAAGA9PpFCEtO6AAAAYD3CCSQRTgAAAGA9wgkkSSEhrDkBAACAtQgn+P8YOQEAAIC1CCeQJIWG8qMAAAAAa/GJFP8fIycAAACwFuEEklhzAgAAAOsRTvD/MXICAAAAaxFOIMn/yAkAAABQmQgnkCTZbL4/CkzrAgAAQGUinEASIycAAACwHuEEknhCPAAAAKxHOIEkwgkAAACsRziBJP/hhDUnAAAAqEyEE0iSQkL4UQAAAIC1+EQKSUzrAgAAgPUIJ5DE3boAAABgPcIJJLHmBAAAANYjnEAS07oAAABgPcIJJLEgHgAAANbjEykkMXICAAAA6xFOIIk1JwAAALAe4QSSuFsXAAAArEc4gSTJZuNHAQAAANbiEykkMXICAAAA6xFOIIk1JwAAALAe4QSSuFsXAAAArEc4gSTCCQAAAKxHOIEkKTSUHwUAAABYi0+k+P9YcwIAAABrEU4gibt1AQAAwHqEE0hizQkAAACsRziBJMIJAAAArEc4gSQpJMT3R4E1JwAAAKhMhBNIYs0JAAAArEc4gSSmdQEAAMB6hBP8f4QTAAAAWItwAkn+p3Wx5gQAAACViXACSf4XxAMAAACViU+kkCSx5AQAAABWI5xAEgviAQAAYD3CCSSx5gQAAADWI5xAEiMnAAAAsB7hBJIIJwAAALAe4QSFEFAAAABgHcIJJHnu1uUdTlhzAgAAgMpEOEEhjJwAAADAOoQTSPI/cgIAAABUJsIJCuHHAQAAANbh0ygkseYEAAAA1iOcoBCmdQEAAMA6hBNIYs0JAAAArEc4QSH8OAAAAMA6fBqFJNacAAAAwHqEExTCtC4AAABYh3ACSaw5AQAAgPUIJyiEcAIAAADrEE4gyTNy4v3jwJoTAAAAVCbCCQph5AQAAADWIZxAEmtOAAAAYD3CCQohnAAAAMA6hBNI4jknAAAAsB7hBIXw4wAAAADr8GkUklhzAgAAAOsRTlAI07oAAABgHcIJJDFyAgAAAOsRTlAI4QQAAADWIZxAkv8nxAMAAACViU+jKIQ1JwAAALAO4QSSWHMCAAAA6wVsONm8ebMGDBighIQE2e12JSUlafHixWVqw+12a/bs2WrXrp2io6NVq1Yt3Xrrrdq1a5fPsYcOHdKLL76o/v37q1GjRoqIiFDdunV100036csvvyzyGk6nU+PHj1fjxo0VGRmpxo0ba/z48XI6nWWu2XqEEwAAAFgnIMNJamqqunbtqs8//1w333yzxowZo/T0dA0bNkzTp08vdTujR4/W2LFjVVBQoLFjx2rAgAH66KOP1KlTJ/34449ex7700ksaN26cfvnlF/Xr108PPfSQunbtqg8//FDXX3+9li5d6tN+dna2evTooRdeeEGtWrXSuHHj1Lp1a73wwgvq0aOHsrOzy/1eVBZGTgAAAGC1MKs7cL78/HyNHDlSNptNaWlpat++vSQpJSVF1113nVJSUnTLLbeoRYsWxbazbt06zZ07V926ddOqVasUGRkpSbrzzjvVr18/jRkzRuvXrzePT0pKUlpamrp16+bVzueff64+ffpozJgxuvHGG812JGnmzJnaunWrJkyYoKefftrcnpKSoieffFIzZ87U5MmTy/2eVB7vrMqaEwAAAFSmgBs5Wbt2rfbs2aPbb7/dDCaSFBcXp8cff1z5+fmaP39+ie3MnTtXkjR16lSvQNGnTx8lJycrLS1NO3fuNLf//ve/9wkmktStWzf16tVLJ0+e1Pbt283thmFo3rx5io2N1RNPPOF1zsSJE5WQkKDXXnutynzAZ+QEAAAAVgu4cJKamipJ6t+/v88+z7bCIx7FtWO329WlSxeffcnJyaVuR5LCw8MlSWFh/xto2rVrlw4fPqwuXbrIbrd7HR8VFaXu3bvr0KFD2r17d6muERgIJwAAALBOwE3r8ixW9zdtKyEhQTVr1vS7oL2w7OxsHTlyRFdeeaVCQ0N99nvaLqkdSfr111+1evVq1a1bV23bti1VP8+/RlHH5ObmKjc31/zes4je5XLJ5XKV2LeKVFCQr/PDSX5+fqX3wyqeOoOl3sKCuXYpuOsP5tql4K4/mGuXgrt+ag/O2iXr6y/tdQMunGRmZkqS4uPj/e53OBw6ePBgudsofFxRXC6X7rjjDuXm5mrmzJleQacirjFjxgy/a1JWrlypmJiYYvtW0Y4ejdH54WTDhg06duxYpfbDaqtWrbK6C5YJ5tql4K4/mGuXgrv+YK5dCu76qT14WVV/Tk5OqY4LuHASKNxut+6++26lpaXp3nvv1R133FHh15g4caLGjx9vfu90OtWwYUP179/fDDeVZffufJ0/y69Lly7q1KlTpfbDKi6XS6tWrVK/fv3MaXzBIphrl4K7/mCuXQru+oO5dim466f24Kxdsr7+0j5mI+DCiWckoqgRB6fTWeRoRVnaKHzc+QzD0L333qtFixZp+PDh+sc//lHh15CkyMhIr8X6HuHh4ZX+Q3NuOY3tvG1hQfeP14r3PlAEc+1ScNcfzLVLwV1/MNcuBXf91B6ctUvW1V/aawbcgvji1oNkZGQoPT29xNsI2+121atXT3v37lVBQYHP/uLWi7jdbt1zzz16/fXXNXToUC1YsEAhIb5vU0nrVkpakxJouFsXAAAArBZw4aRHjx6Szq27OJ9nm+eYktrJzs7Wxo0bffatWLHCbztut1sjR47U/Pnzddttt+nNN9/0u6BeOhc6EhMTtXHjRp+HLZ49e1ZpaWlKTExU8+bNS+xr4PAOJ1XlNsgAAAC4NARcOOnTp4+aNWumxYsXa+vWreb2rKwsTZkyRWFhYRoxYoS5PT09XTt27FB6erpXO6NGjZIkPfbYY8rLyzO3r1mzRitWrFD37t3VsmVLc7tnxGT+/Pm65ZZbtGjRoiKDiSTZbDaNHDlSp0+f1pNPPum1b8aMGcrIyDAfJlkVnOtmwP04AAAAIIgE3JqTsLAwzZs3T8nJyerWrZuGDh0qh8OhZcuWae/evZo6dapXqJg9e7YmT56slJQUTZo0ydzeq1cvjRw5UvPmzVP79u01cOBAHT16VEuWLJHD4dCrr77qdd0nn3xSCxYsUGxsrFq2bKmpU6f69G3w4MG6+uqrze8nTJigjz76SDNnztSWLVvUoUMHbdu2TcuXL9fVV1+tCRMmVPj7c3FVjSAFAACAS1PAhRPpXLDYsGGDUlJStHTpUuXl5alNmzaaMmWKhg0bVup25syZo3bt2mnOnDmaNWuWYmNjNWjQIE2bNs0r4EjSvn37JEmnT5/WtGnT/LbXpEkTr3Bit9uVmpqqyZMn67333lNqaqrq1q2rcePGKSUlxefhjIGMNScAAACwWkCGE0lKSkrS8uXLSzxu0qRJXiMmhYWEhGjs2LEaO3Zsie0sWLBACxYsKGMvz92N6/nnn9fzzz9f5nMDD2tOAAAAYB0WGUASIycAAACwHuEEhfDjAAAAAOvwaRSSGDkBAACA9QgnKIQ1JwAAALAO4QSSGDkBAACA9QgnKIRwAgAAAOsQTiCJJ8QDAADAenwaRSGsOQEAAIB1CCeQxJoTAAAAWI9wgkIIJwAAALAO4QSFEE4AAABgHcIJJPlfEM+aEwAAAFQmwgkKYeQEAAAA1iGcQBIL4gEAAGA9wgkKIZwAAADAOoQTSPI/csKaEwAAAFQmwgkK4ccBAAAA1uHTKCSx5gQAAADWI5ygEMIJAAAArEM4gSTWnAAAAMB6hBMUwo8DAAAArMOnUUhizQkAAACsRzhBIYQTAAAAWIdwAkmsOQEAAID1CCcohJETAAAAWIdwAkmekRN+HAAAAGAdPo2iEEZOAAAAYB3CCSSx5gQAAADWI5ygEEZOAAAAYB3CCSTxnBMAAABYj3CCQvhxAAAAgHX4NApJrDkBAACA9QgnKIRpXQAAALAO4QSSWHMCAAAA6xFOUAjTugAAAGAdwgkk8YR4AAAAWI9PoyiEaV0AAACwDuEEklhzAgAAAOsRTlAIa04AAABgnXKFk9OnT+vXX39Vfn6+1/YlS5Zo2LBhuvfee7V169byXAKVhJETAAAAWC2sPCc/8sgjWrhwoY4ePaqwsHNNvfrqq3rwwQfN37q/8847+vrrr9WqVavy9xYXGQNpAAAAsE65Po1+/vnn6tu3r+x2u7ltxowZql+/vtLS0rR06VIVFBTomWeeKXdHcXExcgIAAACrlWvk5NChQ+rbt6/5/fbt23Xw4EHNnDlTXbt2lSS99957Wr9+ffl6iUrCmhMAAABYp1wjJ2fOnFFERIT5/YYNG2Sz2dS/f39zW7NmzXTo0KHyXAaVwN/IyXfffWdJXwAAABCcyhVOGjRo4PUB9pNPPlFCQoLatm1rbjtx4oRiY2PLcxlUmkyv78aPH29RPwAAABCMyjWt64YbbtDLL7+sv/zlL4qKitJnn32mO+64Qzbb/34Dv2PHDjVq1KjcHcXFde6vLL+kwwAAAICLplzhZOLEifr444/13HPPSZLq1q2ryZMnm/t//fVXbdy4UX/84x/L10tUEhbEAwAAwDrlCid169bVDz/8oDVr1kiSunfvLofDYe7PysrSc889p+Tk5PL1EhedjVwCAAAAi5UrnEhSdHS0fvOb3/jd16ZNG7Vp06a8lwAAAAAQBModTvz5z3/+o3//+9+KiYnRH/7wByUmJl6My6ACMXICAAAAq5Xrbl0PP/ywoqKidPLkSXPbe++9p27dumnGjBl6/PHHdc0113Ar4SqDhAIAAADrlCucrFu3Tr169VL16tXNbY8//rji4+P1xhtvaObMmTpx4oS5YB6Bi5ETAAAAWK1c4eTXX39VixYtzO937dqln3/+WX/84x81fPhwPfzwwxowYIA+/fTTcncUAAAAwKWtXOHk9OnTXg9Y9Dwh/oYbbjC3tW7dWgcPHizPZVAJGDkBAACA1coVTurVq6eff/7Z/P6zzz5TbGysOnToYG5zOp2KjIwsz2VgIcMwrO4CAAAAgkS57tbVo0cPvf3223r55ZcVFRWlDz74QL/97W8VGhpqHrN79241aNCg3B3FxXVu5MR3+OTIkSM6deqUWrduXel9AgAAQHAp18jJ3/72N0VHR+uPf/yj7r33XoWHhyslJcXcf/z4caWmpqpLly7l7igqg284qV+/vtq0aaO9e/da0B8AAAAEk3KNnDRv3lw//vij3n//fUnSb37zGzVp0sTcv3//ft1///26/fbby9VJXHznRk6KnsK1YcMGNW3atNL6AwAAgOBT7ocw1qtXTw8++KDffR07dlTHjh3LewkEgLNnz1rdBQAAAFziKuwJ8fn5+dq5c6cyMzPlcDjUqlUrhYVdlAfQwwI5OTlWdwEAAACXuHKtOZGkjIwMjRo1StWqVVPbtm3VtWtXtWvXTtWqVdOoUaN04sSJiugnKkXR07qcTmcl9gMAAADBqFxDGxkZGbruuuu0c+dO1ahRQ926dVPdunV19OhRff3115o3b57Wr1+v//znP15PkUfVk5uba3UXAAAAcIkr18jJlClTtHPnTk2cOFH79+/X8uXLNX/+fH366afav3+//va3v2nXrl2aOnVqRfUXF1XRIyd5eXmV2A8AAAAEo3KFkw8++EC9evXStGnTFBMT47UvOjpaU6ZMUe/evfXBBx+U5zKoNEWHE0ZOAAAAcLGVK5wcPnxY1157bbHHdO7cWYcPHy7PZRAAGDkBAADAxVaucBIfH6/9+/cXe8z+/fsVHx9fnsug0jCtCwAAANYpVzjp2bOn3n33Xa1evdrv/jVr1ujdd99Vz549y3MZVBqmdQEAAMA65bpbV0pKij755BMlJydrwIAB6tGjh+rUqaOjR48qNTVVy5cvV3R0tJ544omK6i8swsgJAAAALrZyhZPWrVtr5cqVGjFihD755BN98sknstlsMoxzv4G/7LLLtHDhQrVp06ZCOouLjWldAAAAsE65H+F+/fXX6+eff9bGjRu1ZcsWOZ1OORwOtW/fXl26dNHs2bP17LPPatmyZRXRX1iEaV0AAAC42ModTiTJZrOpa9eu6tq1q8++b7/9Vh9++GFFXAYXmc0mGUUMnjByAgAAgIutXAviL6bNmzdrwIABSkhIkN1uV1JSkhYvXlymNtxut2bPnq127dopOjpatWrV0q233qpdu3b5PX7RokW677771LFjR0VGRspms2nBggVFtj9p0iTZbDa/r6ioqDL1NTCwIB4AAADWqZCRk4qWmpqq5ORkRUREaMiQIYqPj9eyZcs0bNgw7du3T48++mip2hk9erTmzp2r1q1ba+zYsTp69KiWLFmilStX6osvvlDr1q29jn/ssce0f/9+1axZU/Xq1SvxNsked911l5o0aeK1LSwsIN/aErDmBAAAANYJuE/Q+fn5GjlypGw2m9LS0tS+fXtJ5+4Mdt111yklJUW33HKLWrRoUWw769at09y5c9WtWzetWrVKkZGRkqQ777xT/fr105gxY7R+/Xqvc+bNm6cWLVqocePGeuqppzRx4sRS9XnEiBGX/O2SCScAAAC42AJuWtfatWu1Z88e3X777WYwkaS4uDg9/vjjys/P1/z580tsZ+7cuZKkqVOnmsFEkvr06aPk5GSlpaVp586dXuf07dtXjRs3rqBKLi1M6wIAAMDFFnAjJ6mpqZKk/v37++zzbDt/xKOodux2u7p06eKzLzk5WZ999pnWr1+vli1blq/Dkj7//HN99dVXCg0N1eWXX66+fft6BaKqg2ldAAAAsE6Zw8mAAQPKdPz27dvLdLxnsbq/aVsJCQmqWbNmkQvaPbKzs3XkyBFdeeWVCg0N9dnvabukdkrr/IdM1qtXTwsXLlS/fv2KPS83N9drRMLpdEqSXC6XXC5XhfSttM5dr/hwUtl9qkye2i7lGosSzLVLwV1/MNcuBXf9wVy7FNz1U3tw1i5ZX39pr1vmcPLZZ5+VuTM2m63Ux2ZmZkqS4uPj/e53OBw6ePBgudsofNyFuvrqq7Vw4UL16NFDderU0cGDB/XOO+9o+vTp+u1vf6tNmzbpqquuKvL8GTNmaPLkyT7bV65cqZiYmHL1raJlZWXp008/tbobF92qVaus7oJlgrl2KbjrD+bapeCuP5hrl4K7fmoPXlbVn5OTU6rjyhxO9u7dW+bOXKoGDx7s9X3z5s312GOPqU6dOho1apSmTp2qd999t8jzJ06cqPHjx5vfO51ONWzYUP379zcDVGU5l2bnFXtMWUfNqhKXy6VVq1apX79+Cg8Pt7o7lSqYa5eCu/5grl0K7vqDuXYpuOun9uCsXbK+fs8MoZKUOZxc7AXjntGOokY1nE5nkSMiZWmj8HEV7a677tL999+vjRs3FntcZGSk37Up4eHhFv2jKX5aVzD8Q7buvbdeMNcuBXf9wVy7FNz1B3PtUnDXT+3BWbtkXf2lvWbA3a2ruPUgGRkZSk9PL/E2wna7XfXq1dPevXtVUFDgs7+4dS0VISIiQnFxcaUevgoUxc2+425dAAAAuNgCLpz06NFD0rl1F+fzbPMcU1I72dnZfkcvVqxYUep2LsSuXbuUkZHh82DGwFf0yInb7fYb9AAAAICKEnDhpE+fPmrWrJkWL16srVu3mtuzsrI0ZcoUhYWFacSIEeb29PR07dixQ+np6V7tjBo1StK5p74Xvg3umjVrtGLFCnXv3r1ctxHOysrSd99957M9IyND99xzjyRp6NChF9y+NYoOJxKjJwAAALi4Au45J2FhYZo3b56Sk5PVrVs3DR06VA6HQ8uWLdPevXs1depUr1Axe/ZsTZ48WSkpKZo0aZK5vVevXho5cqTmzZun9u3ba+DAgTp69KiWLFkih8OhV1991efa8+bN04YNGyT97xbI8+bNM5+9MnjwYHMR/IkTJ3TVVVepY8eOatu2rWrXrq1Dhw5p+fLlOnHihPr166dx48ZdnDfJInl5eQF3FzEAAAD8T35+vs6cOWO+cnJydObMGWVlZennn38O+BscBVw4kc4Fiw0bNiglJUVLly5VXl6e2rRpoylTpmjYsGGlbmfOnDlq166d5syZo1mzZik2NlaDBg3StGnT/I6abNiwQQsXLvTatnHjRnNqWJMmTcxwUr16dT3wwAPatGmTPv74Y506dUp2u11t27bV8OHDNXLkSL/PWKnKeBAjAACAZBiG8vPzzWfTZWVlKTc3V3l5eebL8zw7z/cul0tnz57V2bNn5XK5lJeX59WGZ1tOTo5ycnLkcrmUn59vvjzfnz17Vjk5OWabhQOIZ3tREhMTA/6X5wEZTiQpKSlJy5cvL/G4SZMmeY2YFBYSEqKxY8dq7NixpbrmggULtGDBglId63A4NHv27FIdW3UwrQsAAFya8vLylJmZqT179ignJ0dOp1OZmZml+tPz4d8TLs6cOSO32211SSWKiopSdHS0YmJiFB0dLbvdbnWXShSw4QSBh5ETAABQWQzDkNvtVnZ2tjIyMnT69GmdPn1aWVlZcjqd5ssTILKysnz2ebZlZmZe1F+yhoaGKjo6WhEREQoPD1dERIT5yIjIyEhFRESY26Kioszb+fp7xcTEKCYmRhEREQoLC1N4eLjCwsLMV1RUlGJiYhQZGamwsDBFR0ebwcMTQqKjoxUVFaWQkP8tL3e5XFXigdqEExRS/MgJ4QQAAPjjcrmUnZ2t06dP+/zpmaKUnZ0tp9NpbsvJyfE6zvNyOp06deqUMjIyLsqdQu12u+Lj4+VwOEr9p91uN0chPH96gkdYWJgiIiJkK+6ZDCg1wglKjWldAABUfW63W2fOnFF6eroZFvy9MjMzzVdWVlaR4SM7O/ui/wIzMjJScXFxio2NVWxsrBkaPK+4uDjFxcV5hQrPNs/x0dHR2rBhgwYNGhTUD2EMdIQTlBojJwAAVD7DMHT27NlSrY/IyspSXl6e12iEZ2qT5+uL+ZDosLAw2e12xcbGmn96pijZ7XYzLHimLsXGxnqFDs8x1apVU0JCgteaifJyuVyX3M2KLkWEExTCgngAACqCYRjmNKbzw8H5f2ZmZurkyZN+105kZ2crOztb+fn5Fd7HkJAQr2Bw/is+Pt58eaY2FQ4ddrvdZ1tERESF9xPBhXCCQlhzAgAILoZhKCcnxwwJnoXU2dnZOnv2rBkUPGEiJydH2dnZ5poJz7kul8u8A5RnLUVFr5ew2WyKi4srcm2EZyrT+aMUhf+MjIzUpk2b9Jvf/EYJCQleC6aBQEA4gclmI5wAAKqWgoICZWZm6tSpUzp16pROnDhhrqPIyMjwemVmZurMmTM6ceKE/vvf/yo/P18nT568KIuuPUJDQ+VwOHymLxUODA6HQwkJCapWrZr5vedPz+hEfHy87HZ7ucOEy+XSjh075HA4CCYISIQTmMLDp6mgYHWR+5nWBQCoKG6327wzU0mvwiMa52/PzMyskP54pjidf3em80cfPGHBs2YiOjraHJGIjIz0mv5UrVo1xcTEcBcnoAwIJzCFhV1d7H5GTgAA+fn5Ps+SuJBgkZWVVaH9iomJUbVq1VSjRg3Fx8crJiZGCQkJSkhIUPXq1ZWQkGDesSkuLk4//vij+vfvr7p16xIigABCOEGpEU4AoOpwuVzmyML5t4g9deqUvvrqK33//ffmFKgzZ86YT8H2LMIufE52drZcLleFL8wOCwvzuS1sWV6e4FGWW8O6XC5JUrt27bilLBBgCCcwlfQLI6Z1AUDlyc/P93nWRGZmptcaipMnT/q8MjIydOrUKfMD+MUSFRV1wYGi8CsqKooRCwAmwglKjZETACiZ5xaynrs9eRZqF54K5dl26tQpczH3+X9W1LMoPHdtKrwYOyYmRk6nUy1atFD16tUVFxdnPkui8PMnCj97wm63Kzw83Awl3DIWwMVAOEEh/u/WFRUVpbNnzzJyAuCSZRiG8vLyfJ5H4e+ZFJ6Q4bn7kydwePZnZGRU6KhFRESEuV4iLi7OXEdRo0YNc0pT9erVza8L3/UpNjbW77Qll8ulTz/9VAMGDGBaE4CAQjhBiaKjo3X27FlGTgAELMMwzMBQ+HXixAlzFCI9PV0ZGRlmuDh16pR5O1mn03lRpkF5RhkSEhK8bhHrefp1tWrVzOdTeAJItWrVVK1aNa87RgFAsCCcwFTUlN/o6GhlZGQQTgBcVG632xx58LxOnTql7OxsHT9+XCdOnDDXVBRec+E5zu12V0g/oqOjfZ5Dcf7tZAs/l8KzmNszBcozemG321lLAQBlRDhBiaKjoyWxIB5A8QzDMO8EVfjlCQ/+XoX3ZWZmyjCKfxhsSSIjI81wkJCQoJo1ayohIUHR0dGqXr26atSoYYYNu92uH3/8UcnJyeb22NhYhYXxv0YAsAr/BYapuJETiQXxQDBwuVw6evSouSi7uGDhb39FjF5ERUWpWrVqql69uvn8iVq1aplrLAqvrTj/5fnvVWlrdbvdatOmDesuACBAEE5QIsIJUPXk5+fr5MmT5lSo//73vzp69KjOnDmjI0eOKCsrS0ePHtWePXs0adIkcw1GRkZGuUcvwsPDvdZUFPXyrLM4/zjWWABA8CKcoBD/H0iY1gVYx+VyKT09Xenp6WbQOHHihN+vPeszTpw4oczMzAu+ZmhoqN9wUVLY8Lyio6NZawEAuCCEE5SIkROg/AzDUGZmphk0/L3OX+ztubNUeVSrVk01atRQrVq1VK9ePUVHR6tu3brmXaF+/fVX9ejRQzVr1jSnUtWqVUshISEVVDkAAKVHOIGppDUnjJwA5xiGYd6a1t/r+PHjPttOnDih/Pz8C7peSEiIuZjb8yr8vedrz/oMz/aEhIRiF3d7nnXxf//3f6y5AAAEBMIJSsTICS51brdbJ0+eVFZWlo4fP65jx47p2LFjPl8XDhtnz569oGvFxsaqZs2aXq8aNWqoZs2afhd6e7aFhoZWcNUAAAQewglM3K0Ll4r8/HydOHHCDBSFg8XRo0d1+PBhrylUhw8fVkFBQZmvExkZqVq1avmEjaJeNWrUYLE3AADFIJygREzrQiDIycnR4cOHdfjwYWVnZ+vYsWNKT0/Xf//7X/N19OhRHT16VMePH7+gO07Z7XbVrl1btWrVUu3atb1etWrV8gkiMTExLPwGAKACEU5QIkZOcDEYhqGTJ0+agcIzferYsWNe33u+Pn36dJnat9ls5nSpwq9atWqpfv365pqMuLg4/fjjjxoyZIhiY2MvUrUAAKA0CCcokecDW3Z2tsU9QaDzBA7PSEbh0Y0DBw54BZBjx47J5XKVqf2YmBglJiYqLi7OfChf3bp1vV516tRR3bp1VbNmzVKt03C5XDp+/LgiIyMvtGwAAFBBCCcw2Wz+p8FUr15dksr13ARUbXl5eTp69KiOHDmi//73vzpy5IjX14X/LGvgSEhIUJ06dVS7dm3zT8/r/O8dDgfTqAAAuIQRTlCiGjVqSCKcXIpycnK0b98+bd++XU6nU8ePH/cbOE6cOFGmdqtXr666deuqdu3aqlmzpmrXrq2GDRuaIxuFw0dERMRFqg4AAFQ1hBOYivqFdEJCgiTp1KlTldcZlIthGDpx4oQOHTqkQ4cO6eDBg36/zsjIKHWb4eHh5tSpevXq+fzp+bpOnTpMkQIAABeEcIISeaZ15eTkyOVy8bA2ixmGoePHj+vXX3/1ennuZOUJHqW9u1pMTIyqVaum5s2bKzEx0W/wqFu3rqpXr85TwwEAwEVFOEGJPOFEOje1q2bNmhb25tJ35swZHThwwCd8eF4HDhwo9QMAPXemql+/vho0aGB+Xfj7mJgYLV++XAMGDCB4AgAASxFOUKKIiAjZ7XZlZ2cTTsrJ7Xbr2LFjRQaPX3/9VcePHy9VW/Xq1VOjRo3MV/369VWvXj0zdCQmJpZqelVZF7ADAABcLIQTmIq6W1dISIiqVaum7Oxs1p2UwDPlat++fdq3b5/27t2rvXv3avfu3dq3b58OHDhQqufF2O12r+Bx/qt+/fqs6wAAAJccwglKFBoaqvj4eB06dIg7duncbXX379+vXbt2aceOHdqzZ48OHDigffv26ZdffinxeTAhISFKTEz0GzoaNmyoRo0aKSEhgVvmAgCAoEM4gamoz8KecCIFz+2ET58+rb179+qXX37Rnj17tHv3bvO1f/9+ud3uIs+12WxKTExU06ZN1aRJEzVt2lSXXXaZmjZtqsaNGysxMZG1HQAAAH4QTlAiz7QuSWV+3kWgO3bsmH744Qd9//33WrFihV566SXt2LFDhw4dKva86OhoNW/eXC1btlSrVq3UsGFDNW3a1AwgTLkCAAAoO8IJShQaGqomTZpIkvbs2WNtZy6AYRg6cuSItm/fru+//14//PCDdu7cqZ9//lnp6elFnle9enU1adJEzZs393pddtllqlevHtOuAAAAKhjhBCUKDQ1Vq1atJEk7d+60uDfFy8/P188//6xvvvlG33zzjbZu3art27cX+bBBm82mZs2aqVWrVoqIiNCAAQN05ZVX6vLLLzcfPgkAAIDKQTiBqbi7dXnCyc8//1yZXSpWfn6+fvzxR3377bdeYeTMmTM+x4aEhKhly5a68sordeWVV6pVq1Zq0aKFrrjiCsXExMjlcunTTz/lWR8AAAAWIpygRIVHTnbt2qXc3NxKX1Phdru1a9cuffnll/ryyy/1zTffaNu2bX4fRhgbG6v27dvrmmuuUfv27dWuXTtdccUVioqKqtQ+AwAAoGwIJzAVtYQiJCREjRs3Vr169XTkyBF99tlnuvHGGy9qX3JycvTll18qLS1NGzZs0Ndff+33GStxcXG65ppr1KFDB3Xo0EHXXHONWrZsqZCQkIvaPwAAAFQ8wglKFBoaqpCQEN1xxx2aOXOmHnvsMf3f//1fhY6enD17Vps2bdLatWu1Zs0abd682efJ5VFRUerQoYM6d+6sTp06qUOHDrrssssIIgAAAJcIwglKFBoaKkmaMGGCXnvtNX3//feaMGGC/v73v19wm/n5+dq0aZNWr16t9evX6z//+Y9yc3O9jqlfv766d++ubt26qXPnzmrbti3rQQAAAC5hhBOUyHPL3Bo1amjhwoX6zW9+o1mzZqlnz5763e9+V6o2DMPQjz/+qLVr12rdunVau3atzwMd69Wrp549e6pv377q1auXmjRpwu16AQAAggjhBCUqHBAGDhyohx56SM8995yGDx+uefPmaciQIT4h4vTp0/r555+1efNmrV+/XuvWrdPRo0e9jqlevbr69eunXr16qVevXmrRogVhBAAAIIgRTmAq6lbC55s+fbp++OEHffbZZ7r99tv18MMPq02bNrLb7Tp79qx27Nihffv2+ZwXHR2trl27qlevXurTp486dOhgThkDAAAACCcos4iICH344Yd6+umnNW3aNB0+fFiHDx/2Oa527dpq27atunXrpt69eyspKanSb0EMAACAqoNwAlNZZlRFRETo8ccf17hx47R9+3bt2LFDLpdLoaGhat68ua688krVqFHj4nUWAAAAlxzCCcolNjZW1113na677jqruwIAAIAqjgdEwMRadAAAAFiJcAIAAAAgIBBOAAAAAAQEwgkAAACAgEA4gam0zzkBAAAALgbCCQAAAICAQDiBibt1AQAAwEqEEwAAAAABgXACAAAAICAQTgAAAAAEBMIJTOfu1vWDRo16WrVq1bK6OwAAAAgyhBOcp7Vuu22CQkNDre4IAAAAggzhBKbCd+vKz8+3riMAAAAISoQT+DAMwgkAAAAqH+EEfhFOAAAAUNkIJ/BhGJLL5bK6GwAAAAgyhBOYzt2t6xxGTgAAAFDZCCfwYRhSQUGB1d0AAABAkCGcwFT4bl0vvviiJOmRRx6xpjMAAAAIOmFWdwCBxzCkP/3pT/r973+vBg0aWN0dAAAABAnCCYrUsGFDq7sAAACAIMK0LvgwjJKPAQAAACoa4QSmwnfrAgAAACpbwIaTzZs3a8CAAUpISJDdbldSUpIWL15cpjbcbrdmz56tdu3aKTo6WrVq1dKtt96qXbt2+T1+0aJFuu+++9SxY0dFRkbKZrNpwYIFxV7D6XRq/Pjxaty4sSIjI9W4cWONHz9eTqezTH0NJIycAAAAwAoBueYkNTVVycnJioiI0JAhQxQfH69ly5Zp2LBh2rdvnx599NFStTN69GjNnTtXrVu31tixY3X06FEtWbJEK1eu1BdffKHWrVt7Hf/YY49p//79qlmzpurVq6f9+/cX2352drZ69OihrVu3ql+/fho6dKi2bdumF154QevWrdOGDRtkt9sv+H2obIXv1gUAAABUtoAbOcnPz9fIkSNls9mUlpamuXPn6tlnn9W2bdvUpk0bpaSkFDnyUdi6des0d+5cdevWTd9++61mzpyphQsX6pNPPpHT6dSYMWN8zpk3b5727dun48ePa/To0SVeY+bMmdq6dasmTJiglStX6qmnntLy5cv1xBNPaOvWrZo5c+YFvQdWY+QEAAAAVgi4cLJ27Vrt2bNHt99+u9q3b29uj4uL0+OPP678/HzNnz+/xHbmzp0rSZo6daoiIyPN7X369FFycrLS0tK0c+dOr3P69u2rxo0bl6qfhmFo3rx5io2N1RNPPOG1b+LEiUpISNBrr70mg0/6AAAAQKkE3LSu1NRUSVL//v199nm2rV+/vlTt2O12denSxWdfcnKyPvvsM61fv14tW7a8oH7u2rVLhw8fVnJyss/UraioKHXv3l0ffvihdu/erRYtWvhtIzc3V7m5ueb3nnUqLpdLLpfrgvp1oQpfz+XKl8sVXKHKU39lv++BIJhrl4K7/mCuXQru+oO5dim466f24Kxdsr7+0l434MKJZ8qWvw/0CQkJqlmzZonTurKzs3XkyBFdeeWVCg0N9dnvabs008MupJ/nX6OoY2bMmKHJkyf7bF+5cqViYmIuuG8XymbrIenczQgM41ilXz8QrFq1yuouWCaYa5eCu/5grl0K7vqDuXYpuOun9uBlVf05OTmlOi7gwklmZqYkKT4+3u9+h8OhgwcPlruNwsddiIq4xsSJEzV+/Hjze6fTqYYNG6p///7m+ZXlXJrNkyR17NhJAwYE38jJqlWr1K9fP4WHh1vdnUoVzLVLwV1/MNcuBXf9wVy7FNz1U3tw1i5ZX39p72QbcOEkmERGRnqth/EIDw+35IfGZjs3xSwsLExB+G9WknXvfSAI5tql4K4/mGuXgrv+YK5dCu76qT04a5esq7+01wy4BfGekYiiRhycTmeRoxVlaaPwcReiMq5hFdbwAwAAwAoBF06KWw+SkZGh9PT0ItdweNjtdtWrV0979+5VQUGBz/6S1ouUt58VdY3KxnNOAAAAYKWACyc9epxblL1y5UqffZ5tnmNKaic7O1sbN2702bdixYpSt1OUFi1aKDExURs3blR2drbXvrNnzyotLU2JiYlq3rz5BV/DKoycAAAAwAoBF0769OmjZs2aafHixdq6dau5PSsrS1OmTFFYWJhGjBhhbk9PT9eOHTuUnp7u1c6oUaMknXvqe15enrl9zZo1WrFihbp3737BtxGWJJvNppEjR+r06dN68sknvfbNmDFDGRkZ5sMkAQAAAJQs4BbEh4WFad68eUpOTla3bt00dOhQORwOLVu2THv37tXUqVO9QsXs2bM1efJkpaSkaNKkSeb2Xr16aeTIkZo3b57at2+vgQMH6ujRo1qyZIkcDodeffVVn2vPmzdPGzZskCRt377d3OZ59srgwYM1ePBg8/gJEyboo48+0syZM7VlyxZ16NBB27Zt0/Lly3X11VdrwoQJFf8GVQJGTgAAAGCFgAsn0rlgsWHDBqWkpGjp0qXKy8tTmzZtNGXKFA0bNqzU7cyZM0ft2rXTnDlzNGvWLMXGxmrQoEGaNm2a31GTDRs2aOHChV7bNm7caE4Na9KkiVc4sdvtSk1N1eTJk/Xee+8pNTVVdevW1bhx45SSkuLzcMZAZ7ORSgAAAGCdgAwnkpSUlKTly5eXeNykSZO8RkwKCwkJ0dixYzV27NhSXXPBggVasGBBGXp57m5czz//vJ5//vkynRfIGDkBAACAFQJuzQmsw/IYAAAAWIlwAh+MnAAAAMAKhBMAAAAAAYFwAh+MnAAAAMAKhBOYuFsXAAAArEQ4gQ9GTgAAAGAFwglM3K0LAAAAViKcwAcjJwAAALAC4QQAAABAQCCcwAcjJwAAALAC4QQm7tYFAAAAKxFO4IOREwAAAFiBcAITd+sCAACAlQgn8MHICQAAAKxAOAEAAAAQEAgnAAAAAAIC4QQ+mNYFAAAAKxBOYOJWwgAAALAS4QQ+GDkBAACAFQgnMHErYQAAAFiJcAIfjJwAAADACoQTAAAAAAGBcAIfjJwAAADACoQTmFhzAgAAACsRTuCDkRMAAABYgXACE885AQAAgJUIJ/DByAkAAACsQDgBAAAAEBAIJ/DByAkAAACsQDiBibt1AQAAwEqEE/hg5AQAAABWIJzAxN26AAAAYCXCCXwwcgIAAAArEE5gYs0JAAAArEQ4gQ9GTgAAAGAFwgkAAACAgEA4gQ9GTgAAAGAFwglM3K0LAAAAViKcwAcjJwAAALAC4QQm7tYFAAAAKxFO4IOREwAAAFiBcAIAAAAgIBBO4IOREwAAAFiBcAITd+sCAACAlQgn8MHICQAAAKxAOIGJu3UBAADASoQT+GDkBAAAAFYgnAAAAAAICIQT+GDkBAAAAFYgnMDEmhMAAABYiXACH4ycAAAAwAqEE5h4zgkAAACsRDiBD0ZOAAAAYAXCCXwQTgAAAGAFwglMngXxhBMAAABYgXACk2fNCeEEAAAAViCcwAfhBAAAAFYgnMDEtC4AAABYiXACU0gI07oAAABgHcIJfLjdVvcAAAAAwYhwAhML4gEAAGAlwglMrDkBAACAlQgn8EE4AQAAgBUIJzAxcgIAAAArEU5gYs0JAAAArEQ4gQ/CCQAAAKxAOIGJaV0AAACwEuEEJqZ1AQAAwEqEE5gYOQEAAICVCCcweUZOeEI8AAAArEA4gQ9GTgAAAGCFgA0nmzdv1oABA5SQkCC73a6kpCQtXry4TG243W7Nnj1b7dq1U3R0tGrVqqVbb71Vu3btqpDrTpo0STabze8rKiqqTH0NBEzrAgAAgJXCrO6AP6mpqUpOTlZERISGDBmi+Ph4LVu2TMOGDdO+ffv06KOPlqqd0aNHa+7cuWrdurXGjh2ro0ePasmSJVq5cqW++OILtW7dukKue9ddd6lJkyZe28LCAvKtLRYL4gEAAGClgPsEnZ+fr5EjR8pmsyktLU3t27eXJKWkpOi6665TSkqKbrnlFrVo0aLYdtatW6e5c+eqW7duWrVqlSIjIyVJd955p/r166cxY8Zo/fr1FXLdESNGqGfPnhX0DliHkRMAAABYKeCmda1du1Z79uzR7bffbgYESYqLi9Pjjz+u/Px8zZ8/v8R25s6dK0maOnWqGUwkqU+fPkpOTlZaWpp27txZ4de9FBBOAAAAYIWAGzlJTU2VJPXv399nn2db4RGP4tqx2+3q0qWLz77k5GR99tlnWr9+vVq2bFnu637++ef66quvFBoaqssvv1x9+/b1CkRVBSMnAAAAsFLAhRPPYnV/06cSEhJUs2bNYhe0S1J2draOHDmiK6+8UqGhoT77PW0Xbqc8133iiSe8vq9Xr54WLlyofv36FdvP3Nxc5ebmmt87nU5JksvlksvlKvbciuZyucw1J/n5BXK5gut+wp73u7Lf90AQzLVLwV1/MNcuBXf9wVy7FNz1U3tw1i5ZX39prxtw4SQzM1OSFB8f73e/w+HQwYMHy91G4eMu9LpXX321Fi5cqB49eqhOnTo6ePCg3nnnHU2fPl2//e1vtWnTJl111VVF9nPGjBmaPHmyz/aVK1cqJiammAovlraSpN27d+vTT3dYcH3rrVq1yuouWCaYa5eCu/5grl0K7vqDuXYpuOun9uBlVf05OTmlOi7gwklVMnjwYK/vmzdvrscee0x16tTRqFGjNHXqVL377rtFnj9x4kSNHz/e/N7pdKphw4bq37+/GaAqi8vl0rx5RyRJzZo114ABzSr1+lZzuVxatWqV+vXrp/DwcKu7U6mCuXYpuOsP5tql4K4/mGuXgrt+ag/O2iXr6/fMECpJwIUTz8hF4VGNwpxOZ5GjG2Vpo/BxFXVdj7vuukv333+/Nm7cWOxxkZGRftemhIeHW/qPxmYLVXi473S4YGD1e2+lYK5dCu76g7l2KbjrD+bapeCun9qDs3bJuvpLe82Au1uXv/UgHhkZGUpPTy/xNsJ2u1316tXT3r17VVBQ4LPf3/qSiriuR0REhOLi4ko9fBUoWBAPAAAAKwVcOOnRo4ekc+suzufZ5jmmpHays7P9jl6sWLHCp52Kuq50LuBkZGT4PJgx0PEQRgAAAFgp4MJJnz591KxZMy1evFhbt241t2dlZWnKlCkKCwvTiBEjzO3p6enasWOH0tPTvdoZNWqUJOmxxx5TXl6euX3NmjVasWKFunfvbt5G+EKum5WVpe+++86n/xkZGbrnnnskSUOHDr2Qt8ByhBMAAABYIeDWnISFhWnevHlKTk5Wt27dNHToUDkcDi1btkx79+7V1KlTvULF7NmzNXnyZKWkpGjSpEnm9l69emnkyJGaN2+e2rdvr4EDB+ro0aNasmSJHA6HXn311XJd98SJE7rqqqvUsWNHtW3bVrVr19ahQ4e0fPlynThxQv369dO4ceMu+vtVkZjWBQAAACsFXDiRzgWLDRs2KCUlRUuXLlVeXp7atGmjKVOmaNiwYaVuZ86cOWrXrp3mzJmjWbNmKTY2VoMGDdK0adO8gsaFXLd69ep64IEHtGnTJn388cc6deqU7Ha72rZtq+HDh2vkyJF+n7ESyJjWBQAAACsFZDiRpKSkJC1fvrzE4yZNmuQ1YlJYSEiIxo4dq7Fjx1b4dR0Oh2bPnl3qdqsSwgkAAACsEHBrTmAdpnUBAADASoQTmEJCmNYFAAAA6xBO4MPttroHAAAACEaEE5iY1gUAAAArEU5g4m5dAAAAsBLhBD4IJwAAALAC4QQmpnUBAADASoQTmJjWBQAAACsRTuCDcAIAAAArEE5gYloXAAAArEQ4gYlpXQAAALAS4QQmRk4AAABgJcIJTJ5wwhPiAQAAYAXCCQo5N2Ty/vvSypUWdwUAAABBh3ACk2fk5NQpKTnZ0q4AAAAgCBFOYPKEEwAAAMAKhBOYPHfr8mBhPAAAACoT4QRFYmE8AAAAKhPhBKbzp3UxcgIAAIDKRDiBiWldAAAAsBLhBEViWhcAAAAqE+EEppAQRk4AAABgHcIJikQ4AQAAQGUinMB0/oJ4pnUBAACgMhFOYOJuXQAAALAS4QSFsOYEAAAA1iGcwMS0LgAAAFiJcAIT07oAAABgJcIJCmFaFwAAAKxDOIGJaV0AAACwEuEEJqZ1AQAAwEqEE5hsNqZ1AQAAwDqEE5iY1gUAAAArEU5gYuQEAAAAViKcoEiEEwAAAFQmwglMTOsCAACAlQgnMHG3LgAAAFiJcIJCWHMCAAAA6xBOYGJaFwAAAKxEOIGJaV0AAACwEuEEJm4lDAAAACsRTmAKCfFOI0zrAgAAQGUinMB0fjhh5AQAAACViXACE+EEAAAAViKcwMS0LgAAAFiJcAITIycAAACwEuEEJsIJAAAArEQ4gSk0lGldAAAAsA7hBKaQ834aGDkBAABAZSKcwMS0LgAAAFiJcAITd+sCAACAlQgnMDFyAgAAACsRTmAinAAAAMBKhBOYmNYFAAAAKxFOYGLkBAAAAFYinMBEOAEAAICVCCcwMa0LAAAAViKcwMTICQAAAKxEOIGJcAIAAAArEU5gYloXAAAArEQ4gYmREwAAAFiJcAIT4QQAAABWIpzAFBrq/T3TugAAAFCZCCcwnT9ysmCBNf0AAABAcCKcwEQ4AQAAgJUIJzCdH04AAACAykQ4gYlwAgAAACsRTmAKDWUFPAAAAKxDOIEpIoJwAgAAAOsQTmCy2Xy3uVyV3w8AAAAEJ8IJipWdbXUPAAAAECwCNpxs3rxZAwYMUEJCgux2u5KSkrR48eIyteF2uzV79my1a9dO0dHRqlWrlm699Vbt2rWrwq7rdDo1fvx4NW7cWJGRkWrcuLHGjx8vp9NZpr4Gqpwcq3sAAACAYBGQ4SQ1NVVdu3bV559/rptvvlljxoxRenq6hg0bpunTp5e6ndGjR2vs2LEqKCjQ2LFjNWDAAH300Ufq1KmTfvzxx3JfNzs7Wz169NALL7ygVq1aady4cWrdurVeeOEF9ejRQ9mXwLDDJVACAAAAqoiACyf5+fkaOXKkbDab0tLSNHfuXD377LPatm2b2rRpo5SUlGJHPjzWrVunuXPnqlu3bvr22281c+ZMLVy4UJ988omcTqfGjBlT7uvOnDlTW7du1YQJE7Ry5Uo99dRTWr58uZ544glt3bpVM2fOrND3xgqMnAAAAKCyBFw4Wbt2rfbs2aPbb79d7du3N7fHxcXp8ccfV35+vubPn19iO3PnzpUkTZ06VZGRkeb2Pn36KDk5WWlpadq5c+cFX9cwDM2bN0+xsbF64oknvK49ceJEJSQk6LXXXpNhVK1nh3Tt6n3HrldesagjAAAACDphVnfgfKmpqZKk/v37++zzbFu/fn2p2rHb7erSpYvPvuTkZH322Wdav369WrZseUHX3bVrlw4fPqzk5GTZ7Xav46OiotS9e3d9+OGH2r17t1q0aFFifwPF0qUFSkz8X2b95z+lzz+X7rxTqltXCgk5d1cvm837a3+vqiQ/36Zvv62ns2dtCgu4fxUXVzDXLgV3/cFcuxTc9Zem9qr23/Gy8NSfmxu8f/fUbnVvKl9+vk0//lhLAwZY3ZPiBdxfjWfqlL8P9AkJCapZs2aJ07qys7N15MgRXXnllQoNDfXZ72m7cDtlvW5xx59/jaKOyc3NVW5urvm9ZxG9y+WSq5Lv4eu5Xny8Sz/8IM2dG6IXXzz33v30kzRxYqV2xwJhkpKs7oRFgrl2KbjrD+bapeCuP5hrl4K7fmoPXmGqU+cqTZhgzXMiSvvZNuDCSWZmpiQpPj7e736Hw6GDBw+Wu43Cx13IdS/kGuebMWOGJk+e7LN95cqViomJKfK8i2nVqlWSpJ49pa5dbdqzp5p++KGGfvklXjk54TIMyTBs8sxWc7vP/WrNs93zNXAp8/ysAwBQlSQknNWqVV9bcu2cUi5kDrhwEkwmTpyo8ePHm987nU41bNhQ/fv3N8NNZXG5XFq1apX69eun8PDwSr12IAjm+oO5dim46w/m2qXgrj+Ya5eCu35qD87aJU/9Gyyrv7SP2Qi4cOIZiShqxMHpdBY5WlGWNgofdyHXvZBrnC8yMtJrsb5HeHi4Zf9orLx2IAjm+oO5dim46w/m2qXgrj+Ya5eCu35qD87aJevqL+01A+5uXf7Wg3hkZGQoPT29xAXmdrtd9erV0969e1VQUOCz3996kbJet7jji7oGAAAAgKIFXDjp0aOHpHPrLs7n2eY5pqR2srOztXHjRp99K1as8GmnrNdt0aKFEhMTtXHjRp+HLZ49e1ZpaWlKTExU8+bNS+wrAAAAgAAMJ3369FGzZs20ePFibd261dyelZWlKVOmKCwsTCNGjDC3p6ena8eOHUpPT/dqZ9SoUZKkxx57THl5eeb2NWvWaMWKFerevbt5G+ELua7NZtPIkSN1+vRpPfnkk17XnjFjhjIyMsyHOgIAAAAoWcCtOQkLC9O8efOUnJysbt26aejQoXI4HFq2bJn27t2rqVOneoWK2bNna/LkyUpJSdGkSZPM7b169dLIkSM1b948tW/fXgMHDtTRo0e1ZMkSORwOvfrqq+W6riRNmDBBH330kWbOnKktW7aoQ4cO2rZtm5YvX66rr75aEyZMuKjvFQAAAHApCbiRE+lcsNiwYYO6du2qpUuX6pVXXlGNGjW0aNEi/e1vfyt1O3PmzNGsWbNks9k0a9YsffLJJxo0aJC++uortW7dutzXtdvtSk1N1bhx47Rjxw4999xz+v777zVu3DjzIZAAAAAASifgRk48kpKStHz58hKPmzRpkteISWEhISEaO3asxo4dW+HX9YiPj9fzzz+v559/vtTnAAAAAPAVkCMnAAAAAIIP4QQAAABAQCCcAAAAAAgIhBMAAAAAAYFwAgAAACAgEE4AAAAABATCCQAAAICAQDgBAAAAEBAIJwAAAAACAuEEAAAAQEAgnAAAAAAICIQTAAAAAAGBcAIAAAAgIBBOAAAAAAQEwgkAAACAgEA4AQAAABAQCCcAAAAAAgLhBAAAAEBACLO6A/gfwzAkSU6ns9Kv7XK5lJOTI6fTqfDw8Eq/vtWCuf5grl0K7vqDuXYpuOsP5tql4K6f2oOzdsn6+j2fbz2fd4tCOAkgWVlZkqSGDRta3BMAAACg4mVlZSk+Pr7I/TajpPiCSuN2u3X48GHFxcXJZrNV6rWdTqcaNmyoAwcOyOFwVOq1A0Ew1x/MtUvBXX8w1y4Fd/3BXLsU3PVTe3DWLllfv2EYysrKUmJiokJCil5ZwshJAAkJCVGDBg0s7YPD4QjKf7AewVx/MNcuBXf9wVy7FNz1B3PtUnDXT+3BWbtkbf3FjZh4sCAeAAAAQEAgnAAAAAAICIQTSJIiIyOVkpKiyMhIq7tiiWCuP5hrl4K7/mCuXQru+oO5dim466f24Kxdqjr1syAeAAAAQEBg5AQAAABAQCCcAAAAAAgIhBMAAAAAAYFwAgAAACAgEE6C3ObNmzVgwAAlJCTIbrcrKSlJixcvtrpbZXbo0CG9+OKL6t+/vxo1aqSIiAjVrVtXN910k7788ku/5zidTo0fP16NGzdWZGSkGjdurPHjx8vpdBZ5ncWLFyspKUl2u10JCQkaMGCAvv7664tV1gWbOXOmbDabbDabNm3a5PeYS7H+f/3rX+rXr59q1Kih6OhoNW3aVEOHDtWBAwe8jruUajcMQ8uWLVOvXr1Ur149xcTEqFWrVrrvvvv0yy+/+BxfFWtftGiR7rvvPnXs2FGRkZGy2WxasGBBkcdXRo27du3Srbfeqlq1aik6Olrt2rXT7Nmz5Xa7y1Oqj9LW7nK59P7772vEiBG64oorZLfbFRcXp86dO+uVV15RQUFBkdcI1Nqlsv/dF7Z3717FxsbKZrNp9OjRRR4XqPVfSO179+7Vvffea/7s16lTR7169dK7777r9/hArV0qe/27du3SH/7wB7Vo0ULR0dGqX7+++vXrp48++qjIcwKx/kD9PFOZf/cyELTWrVtnREREGLGxscbIkSONhx56yGjatKkhyZg2bZrV3SuTRx55xJBkXHbZZcbdd99t/PWvfzVuuukmIzQ01AgJCTGWLFnidfzp06eNq6++2pBk9OvXz3jkkUeM//u//zMkGVdffbVx+vRpn2tMmzbNkGQ0atTIGD9+vDFq1CjD4XAYERERxrp16yqp0pL9+OOPRmRkpGG32w1Jxn/+8x+fYy61+t1utzFq1CjzZ+D+++83HnnkEeOOO+4wGjVqZHz++efmsZda7ePHjzckGfXq1TNGjx5tTJgwwUhOTjZsNpsRFxdnbN++3Ty2qtbeuHFjQ5JRs2ZN8+v58+f7PbYyavzhhx+M+Ph4Izw83Bg2bJgxYcIEo23btoYk495777Wk9p9++smQZMTFxRk33nijMWHCBOO+++4zEhMTDUnGoEGDDLfbXaVqL0v953O73UaPHj3M/w7ed999fo8L5PrLWvvKlSuNmJgYIyYmxrjtttuMiRMnGqNHjzauv/56Y9SoUT7HB3LthlG2+jdt2mRER0cbYWFhxu9//3vjkUceMf7whz8Y8fHxhiRj0qRJPucEav2B+Hmmsv/uCSdByuVyGZdddpkRGRlpfPvtt+Z2p9NptGnTxggLCzN27txpYQ/L5v333zfS0tJ8tqelpRnh4eFG9erVjbNnz5rbn3jiCUOSMWHCBK/jPdufeOIJr+07d+40wsLCjJYtWxqnTp0yt3///fdGTEyMcdlllxkul6uCqyq7/Px8o1OnTkZSUpIxfPjwIsPJpVb/3//+d0OS8cADDxj5+fk++wv37VKq/ciRI0ZISIjRpEkTIzMz02vfCy+8YEgy/vCHP5jbqmrtq1atMvbt22cYhmHMmDGj2A8plVFj9+7dDUnGJ598Ym7Ly8sz+vTpY0gy1q5dW55yvZS29oMHDxqvvPKKkZ2d7bX99OnTRseOHQ1JxtKlS732BXrthlG2v/vC/v73vxthYWHG888/X2Q4CfT6y1L7r7/+ajgcDqNFixbG/v37ffafX0eg124YZav/hhtuMCQZH374odf2/fv3Gw6Hw4iOjvb6DBDI9Qfi55nK/rsnnASpFStW+Hxw8XjnnXcMScbEiRMt6FnF69+/vyHJ2Lx5s2EY536jlpiYaMTGxvr8RuHMmTNGQkKCUb9+fa/fMk6cONGQZCxcuNCn/dGjRxuSjBUrVlzcQkph2rRpRkREhPH9998bd911l99wcqnVn5OTY1SvXt1o1qxZiR+UL7Xa//Of/xiSjGHDhvns27lzpyHJGDhwoGEYl07txX1IqYwaf/75Z0OS0atXL5/jN23aZEgyhg4dWo4Ki1aWD+eFLV682AzvhVWl2g2j9PXv2rXLiImJMR599FFj3bp1RYaTqlR/SbV7+rtmzZpStVeVajeMkutv1aqVYbPZjNzcXJ99119/vSHJOH78uLmtqtXvYcXnGStqZ81JkEpNTZUk9e/f32efZ9v69esrs0sXTXh4uCQpLCxM0rl5k4cPH1aXLl1kt9u9jo2KilL37t116NAh7d6929xe3PuVnJwsyfr36/vvv9fkyZP12GOPqU2bNkUed6nVv2rVKp08eVKDBw9WQUGBli1bpqeeekr/+Mc/vGqQLr3aW7RooYiICG3cuFFZWVle+z799FNJUu/evSVderX7Uxk1Fnd8UlKSqlWrFlDvieT730CPS7F2t9utP/zhD2rcuLGeeOKJYo+9VOo3DENLly5VjRo11Lt3b33zzTd6/vnn9eyzz2r16tV+1wRcKrV7tGnTRoZhaOXKlV7bDxw4oO+//15t27ZVzZo1ze1VtX4rPs9YUXtYyYfgUrRr1y5J5z7cnC8hIUE1a9Y0j6nKfv31V61evVp169ZV27ZtJRVfe+Htu3bt8vo6NjZWdevWLfZ4q+Tn55sLYf/6178We+ylVr9nAV9YWJiuuuoq/fzzz+a+kJAQjRs3Ts8++6xXHy+V2mvUqKFp06bpL3/5i6644gr99re/VVxcnLZv367Vq1dr1KhRGjt2rFcfL5Xa/amMGou7hs1mU/PmzfX1118rJydHMTEx5aim4rz++uuSfD9cXIq1v/jii/riiy+0YcMGRUZGFnvspVL/3r17dfLkSXXq1EljxozRP/7xD6/97du310cffaQGDRqY2y6V2j2mTJmiDRs26Pe//71uvPFGNW/eXMePH9eyZcvUuHFjLV261Ov4qli/VZ9nrKidkZMglZmZKUmKj4/3u9/hcJjHVFUul0t33HGHcnNzNXPmTIWGhkoqXe2Fj/N8XZbjK9v06dO1bds2vf766+ZvVopyqdV/7NgxSdJzzz0nh8Ohr776SllZWUpLS1PLli313HPP6dVXX/Xq46VSuyQ9/PDDeuutt5SZmalXX31VM2fO1PLly9WpUycNHz7c/Hm4FGs/X2XUeCHXsNI///lPLV++XL1799aAAQO89l1qte/cuVOPPfaY/vSnP+m6664r8fhLpX7PfwO//fZbLVq0SPPnz9fJkyfNO3dt2bJFN998s9c5l0rtHq1bt9amTZvUrl07vffee3rqqaf02muvSZJ5B6/Cqlr9Vn6esaJ2wgkuSW63W3fffbfS0tJ077336o477rC6SxfNtm3bNHXqVD388MO65pprrO5OpfNMWYiIiNAHH3ygTp06KTY2Vt26ddN7772nkJAQPffccxb38uKZOnWqRowYoYkTJ+rAgQM6ffq0NmzYoPz8fPXq1UvLli2zuouwyCeffKIHH3xQjRs31qJFi6zuzkXldrs1YsQIJSYmaurUqVZ3p1J5/htYUFCgKVOmaMSIEUpISFCTJk30z3/+U507d9aXX36pDRs2WNzTi+frr79W165dVb16dX3zzTfKzs7WL7/8onvuuUfjx4/XLbfcYnUXL1gwfZ7xIJwEKU8CLirpOp3OIlNyoDMMQ/fee68WLVqk4cOH+wxxl6b2wsd5vi7L8ZXprrvu0mWXXaZJkyaV6vhLrX7PdTt27KjExESvfW3atFGzZs20Z88enTp16pKrfe3atXr88cf14IMP6tFHH1WDBg1kt9vVpUsX/fvf/1Z0dLTGjRvn1cdLpXZ/KqPG0l7D89tEq6xYsUI33XST6tSpo7Vr16pevXo+x1xKtc+aNUubNm3SvHnzSj215FKpv3Aff/vb3/rsHzRokCR5PcPiUqldOjeqcNttt8lms+mDDz7QNddco5iYGDVt2lTPPPOMbrvtNv3rX//SunXrzHOqSv2B8HnGitoJJ0GquPniGRkZSk9PL3IOYyBzu92655579Prrr2vo/2vvbmObKts4gP/bbjswSjvEzbk56KDNiNNlQV7GW9bNvZQElQ+YiRkZSTF8MJFskEWDyYwSjDExavxiMAK6RDQkxg/IquNlTEmEGFEja+MyYGQowmDDwepmdz0f9pzzrPSs23hGe9r9f0k/cJ+r3f1v2dm5tnPOvXkzDhw4ALM5/L/5ROfK651f6XK5MDAwgD///HNS9bH0888/w+/3Y9asWdrCiyaTCQcPHgQArFq1Sttpj51nsuQvKCgAAGRkZOhuV8cHBweTLvuRI0cAAGVlZRHbMjMz8fjjj6O7uzvs+zlZsuuJRcZoX0NE0NnZiZycnIiLU2OppaUFGzduxIMPPogTJ05g0aJFunXJlP3cuXMQEZSVlYXtB9XvjQ8//BAmkwkbN27UnpMs+Z1Op3aaj95+cOw+UJUs2QHA7/ejq6sLK1eu1G1M1ZuC/Pjjj9pYIuQ3yvFMPLKzOZmhSktLASDizhZjx9SaRDEyMoJt27Zh//79qKmpwaeffqrtsMdyuVzIycnB999/j9u3b4dtCwaDOHXqFHJycuB0OrXxaO+Xz+cLq4k1r9er+1B3KE8//TS8Xi8cDgeA5MuvHnx0dHREbBseHkZnZyfmzJmDzMzMpMs+NDQEALh27ZrudnVcUZSky64nFhndbve49WfOnEFfX19c3xO1MZk3bx5OnDgRlvVuyZS9tLRUdz+oXmezZMkSeL1eVFZWhj0HSPz8iqJg9erVAIDz589HbFfH1J8BQPJkB6a2H1QZPb+Rjmfi8tlP642JKWEMDw/LokWLRFEU+emnn7TxsYswBgKB+E1wikKhkGzdulUAyLPPPjvhehdTXbQoEAgYYjG6qRhvnROR5Muv3vt93759YeOvv/66AJDa2lptLJmyf/bZZwJACgsLw+YmInLgwAEBIE888YQ2lgzZp3sRxnvJON6CZBUVFYL7sCCZaqLsR48eFUVRJDs7W/x+/4Svl0jZRe5tnZdo65wkUv6Jsqtr2Tz55JNhC/R1dHRIenq6zJ07V27cuKGNJ1J2kej5g8Gg2O12MZvNEesu9fT0SE5OjgCQX375RRs3cn4jHs/E+rNnczKDHT9+XFJTU8VqtcoLL7wgO3fulPz8fAEge/bsiff0pqSpqUkAiNVqld27d0tTU1PEY2wTNjAwIMXFxQJAKisr5eWXX9ZWmC0uLo5YzEhEZM+ePQJAFixYIA0NDbJ9+3ax2WySmpp6X3fK9ypac5Js+Ts7OyUrK0vw30UHd+7cKeXl5QJAFi5cKH/88YdWm0zZ//33X3G73QJAMjMzxev1yq5du6SyslIAiKIo0t7ertUnavZ9+/ZJXV2d1NXVydKlSwWArFmzRhv78ssvY5rxt99+E7vdLmlpaVJbWyuNjY1SVFQkAGTbtm1xyd7R0SGKoggAee6553T3gXoHdkbOPpX844nWnIgYO/9Uso+MjMimTZsEgBQUFMhLL70kdXV1YrVaxWw2S3Nzc0Jln2r+jz76SACI2WyWp556ShobG6Wurk5sNptAZwFSI+c34vFMrD97Nicz3A8//CAej0fsdrvMnj1bli1bprsTMzr1QDza4+4fzH19fVJfXy95eXmSmpoqeXl5Ul9fH/Eb6LGam5tl2bJlMnv2bLHb7eLxeOTMmTP3Od29idaciCRf/u7ubtm6datkZ2dreV588UW5evVqRG0yZQ8Gg/LWW2/J0qVLJT09XVJSUiQ3N1eef/55+fXXXyPqEzH7RN/fTU1NYfWxyBgIBGTTpk0yf/58URRFCgsL5f3335dQKDRdsUVk8tnVg/Boj9LS0oTKPpX845moORExbv6pZh8eHpZ33nlHCgsLRVEUsdlsUlVVJSdPnhz3axg1u8jU87e2tsqGDRskMzNTLBaL2Gw2Wbdune5K6Coj5jfq8UwsP3uTiAiIiIiIiIjijBfEExERERGRIbA5ISIiIiIiQ2BzQkREREREhsDmhIiIiIiIDIHNCRERERERGQKbEyIiIiIiMgQ2J0REREREZAhsToiIiIiIyBDYnBARERERkSGwOSEiIpoGDocDDocj3tMgIkpobE6IiMgwLl68CJPJFPVRXFwc72kSEdF9khLvCRAREd1t8eLFqK2t1d2WnZ0d49kQEVGssDkhIiLDcTqdeO211+I9DSIiijGe1kVERAnLZDLB7Xbj8uXLqKmpwfz58zFnzhy43W6cPn1a9zm9vb2or69Hfn4+FEVBVlYWampqcP78ed36oaEhvPfee1ixYgXmzp0Lq9WKRx99FA0NDbh582ZE/e3bt9HQ0IDc3FwoioKioiIcPnx4WnMTESUrk4hIvCdBREQEjF5zkp+fj+rqarS0tExYbzKZUFRUhJs3b+Lhhx9GeXk5enp68PnnnwMAfD4f3G63Vt/b24uSkhJ0dnbC7XajpKQEFy9exOHDh6EoCr799lusWrVKqw8Gg6iursapU6fgcrng8XigKAp+//13fPPNNzh9+rR2DYzD4cDw8DAcDgdu3LiBiooK3LlzB4cOHcLg4CBaWlpQVVU1re8XEVGyYXNCRESGoTYn0a45KSkpgcfjATDanADAli1bcPDgQe3fbW1tKCsrw+LFixEIBGA2j54o4PV68fHHH+OVV17B3r17tdf0+XzweDxwuVzw+/1afWNjI95++21s2bIF+/fvh8Vi0Z7T398Pi8UCq9UKYLQ5uXTpEp555hl88cUXSEtLAwAcO3YMFRUVk264iIhmMjYnRERkGGpzEs2OHTvw7rvvAhhtTiwWCy5cuIC8vLywug0bNuDIkSNob2/H2rVrMTQ0hIyMDKSnp6O7uxvp6elh9R6PBz6fT6sPhUJ44IEHYDKZcOHCBcybNy/qvNTmpKurKyKDw+HA33//jd7e3km+E0REMxOvOSEiIsOprq6GiOg+1MZEtXDhwojGBADWrVsHADh37hwAwO/3Y3BwECtWrIhoTABop3+Nrb916xaWL18+YWOiysjI0G2uHnnkEfT19U3qNYiIZjI2J0RElNCysrJ0xx966CEAo6dfAcCtW7fCxu+m3qJYrVebidzc3EnPxW63646npKRgZGRk0q9DRDRTsTkhIqKE9tdff+mOX716FcD/GgabzRY2Pl69WpeRkQEA6Onpmba5EhFRdGxOiIgooV26dAmXL1+OGG9vbwcA7W5aS5YswaxZs3D27FncuXMnor6trS2svqCgADabDWfPntW9ZTAREU0/NidERJTQQqEQdu/ejbH3d2lra8PXX38Np9OJ1atXAwDS0tKwefNmXL9+HW+++WbYa7S2tuLo0aNwOp1Ys2YNgNFTsbZv347+/n7s2LEDoVAo7Dn9/f0YGBi4z+mIiGYW3q2LiIgMYzK3EgagrR6vt87JlStXcOjQIQCR65xcu3YNJSUl6OrqQnl5OVauXKmtc5Kamgqfz4e1a9dq9cFgEFVVVWhvb4fL5cL69euhKAq6urrQ0tKC7777LmydEzXD3dxuN9ra2sAfuURE0bE5ISIiw5jMrYQBaAf5JpMJpaWl+OSTT7Br1y60trYiGAxi+fLl2Lt3r/ZXkLGuX7+ON954A1999RWuXLkCu90Ot9uNpqYmPPbYYxH1//zzDz744AM0NzcjEAjAYrFgwYIFWL9+PV599VXt2hQ2J0RE/z82J0RElLDU5uTkyZPxngoREU0DXnNCRERERESGwOaEiIiIiIgMgc0JEREREREZQkq8J0BERHSveNkkEVFy4V9OiIiIiIjIENicEBERERGRIbA5ISIiIiIiQ2BzQkREREREhsDmhIiIiIiIDIHNCRERERERGQKbEyIiIiIiMgQ2J0REREREZAj/AU8Wm5h9R87EAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 結果確認\n",
    "evaluate_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7b9c7",
   "metadata": {},
   "source": [
    "### モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afa309a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model.pth'\n",
    "torch.save(net.state_dict(), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
